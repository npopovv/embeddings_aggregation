{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYFWRTRTU5Jz",
        "outputId": "abe703ea-a91a-4b08-9397-c9d52ad8cb4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch-lifestream in /usr/local/lib/python3.11/dist-packages (0.6.0)\n",
            "Requirement already satisfied: duckdb in /usr/local/lib/python3.11/dist-packages (from pytorch-lifestream) (1.1.3)\n",
            "Requirement already satisfied: hydra-core>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from pytorch-lifestream) (1.3.2)\n",
            "Requirement already satisfied: numpy>=1.21.5 in /usr/local/lib/python3.11/dist-packages (from pytorch-lifestream) (1.26.4)\n",
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.11/dist-packages (from pytorch-lifestream) (2.3.0)\n",
            "Requirement already satisfied: pandas>=1.3.5 in /usr/local/lib/python3.11/dist-packages (from pytorch-lifestream) (2.2.2)\n",
            "Requirement already satisfied: pyarrow>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from pytorch-lifestream) (18.1.0)\n",
            "Requirement already satisfied: pytorch-lightning>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lifestream) (2.5.0.post0)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from pytorch-lifestream) (1.6.1)\n",
            "Requirement already satisfied: torch>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lifestream) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchmetrics>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lifestream) (1.6.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from pytorch-lifestream) (4.48.3)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from hydra-core>=1.1.2->pytorch-lifestream) (4.9.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from hydra-core>=1.1.2->pytorch-lifestream) (24.2)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from omegaconf->pytorch-lifestream) (6.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.5->pytorch-lifestream) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.5->pytorch-lifestream) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.5->pytorch-lifestream) (2025.1)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning>=1.6.0->pytorch-lifestream) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning>=1.6.0->pytorch-lifestream) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning>=1.6.0->pytorch-lifestream) (4.12.2)\n",
            "Requirement already satisfied: lightning-utilities>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning>=1.6.0->pytorch-lifestream) (0.14.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->pytorch-lifestream) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->pytorch-lifestream) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->pytorch-lifestream) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->pytorch-lifestream) (3.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->pytorch-lifestream) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->pytorch-lifestream) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->pytorch-lifestream) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->pytorch-lifestream) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->pytorch-lifestream) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->pytorch-lifestream) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->pytorch-lifestream) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->pytorch-lifestream) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->pytorch-lifestream) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->pytorch-lifestream) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->pytorch-lifestream) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->pytorch-lifestream) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->pytorch-lifestream) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->pytorch-lifestream) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->pytorch-lifestream) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->pytorch-lifestream) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.12.0->pytorch-lifestream) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers->pytorch-lifestream) (0.28.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->pytorch-lifestream) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers->pytorch-lifestream) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->pytorch-lifestream) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers->pytorch-lifestream) (0.5.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning>=1.6.0->pytorch-lifestream) (3.11.13)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.10.0->pytorch-lightning>=1.6.0->pytorch-lifestream) (75.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.3.5->pytorch-lifestream) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.12.0->pytorch-lifestream) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->pytorch-lifestream) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->pytorch-lifestream) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->pytorch-lifestream) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->pytorch-lifestream) (2025.1.31)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.6.0->pytorch-lifestream) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.6.0->pytorch-lifestream) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.6.0->pytorch-lifestream) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.6.0->pytorch-lifestream) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.6.0->pytorch-lifestream) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.6.0->pytorch-lifestream) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.6.0->pytorch-lifestream) (1.18.3)\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "if \"google.colab\" in str(get_ipython()):\n",
        "    ! {sys.executable} -m pip install pytorch-lifestream"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "import pytorch_lightning as pl\n",
        "import numpy as np\n",
        "from datetime import timedelta\n",
        "from torch import tensor\n",
        "\n",
        "from functools import partial\n",
        "from ptls.nn import TrxEncoder, RnnSeqEncoder\n",
        "from ptls.frames import PtlsDataModule\n",
        "from ptls.frames.coles import CoLESModule\n",
        "from ptls.frames.coles import ColesDataset\n",
        "from ptls.frames.coles.split_strategy import SampleSlices\n",
        "from ptls.data_load.datasets import MemoryMapDataset\n",
        "from ptls.data_load.datasets import inference_data_loader\n",
        "from ptls.data_load.iterable_processing import SeqLenFilter\n",
        "from ptls.preprocessing import PandasDataPreprocessor\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pickle\n",
        "from matplotlib import pyplot as plt\n",
        "from ptls.frames.coles.losses import ContrastiveLoss\n",
        "from ptls.frames.coles.sampling_strategies import HardNegativePairSelector\n",
        "import pickle"
      ],
      "metadata": {
        "id": "YFVCmtPbWLwd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmFOYWsrV67a",
        "outputId": "0059b717-4163-412e-af54-7aa59d923c33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "source_data = pd.read_csv('https://huggingface.co/datasets/dllllb/age-group-prediction/resolve/main/transactions_train.csv.gz?download=true', compression='gzip')\n",
        "source_data.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "OT4hlKGgVw2B",
        "outputId": "7a1382b3-c672-42ab-fcbc-1c41f481a578"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   client_id  trans_date  small_group  amount_rur\n",
              "0      33172           6            4      71.463\n",
              "1      33172           6           35      45.017"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0f08cce7-76dd-4e5a-81f6-c34b7a128d52\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>client_id</th>\n",
              "      <th>trans_date</th>\n",
              "      <th>small_group</th>\n",
              "      <th>amount_rur</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>33172</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>71.463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>33172</td>\n",
              "      <td>6</td>\n",
              "      <td>35</td>\n",
              "      <td>45.017</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0f08cce7-76dd-4e5a-81f6-c34b7a128d52')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0f08cce7-76dd-4e5a-81f6-c34b7a128d52 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0f08cce7-76dd-4e5a-81f6-c34b7a128d52');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c0ab5112-bf0e-42b3-92ac-836aa3c09e76\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c0ab5112-bf0e-42b3-92ac-836aa3c09e76')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c0ab5112-bf0e-42b3-92ac-836aa3c09e76 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "source_data"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"https://huggingface.co/datasets/dllllb/age-group-prediction/resolve/main/train_target.csv?download=true\"\n",
        "df_target = pd.read_csv(path)\n",
        "df_target = df_target.set_index(\"client_id\")\n",
        "df_target.rename(columns={\"bins\": \"target\"}, inplace=True)\n",
        "df_target.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "NePJ8bpu_INe",
        "outputId": "cdfa4008-7e75-4f5c-ca93-ee096313ef95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           target\n",
              "client_id        \n",
              "24662           2\n",
              "1046            0\n",
              "34089           2\n",
              "34848           1\n",
              "47076           3"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b5cfa0e3-6183-4bd9-95fd-0827a149bd2b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>client_id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>24662</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1046</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34089</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34848</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47076</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b5cfa0e3-6183-4bd9-95fd-0827a149bd2b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b5cfa0e3-6183-4bd9-95fd-0827a149bd2b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b5cfa0e3-6183-4bd9-95fd-0827a149bd2b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-65180db1-4735-4e19-8651-4c32f2c6432e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-65180db1-4735-4e19-8651-4c32f2c6432e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-65180db1-4735-4e19-8651-4c32f2c6432e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_target",
              "summary": "{\n  \"name\": \"df_target\",\n  \"rows\": 30000,\n  \"fields\": [\n    {\n      \"column\": \"client_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14448,\n        \"min\": 4,\n        \"max\": 49998,\n        \"num_unique_values\": 30000,\n        \"samples\": [\n          36627,\n          16901,\n          23218\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0,\n          3,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "id_col = 'client_id'\n",
        "date_col = 'trans_date'\n",
        "\n",
        "NUM_EXP = 102\n",
        "\n",
        "numerical = ['amount_rur']\n",
        "categorical = ['small_group', 'trans_date']\n",
        "\n",
        "emb_values = {'small_group': 202, 'trans_date': 730}"
      ],
      "metadata": {
        "id": "JdbU12hOa_FV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def generate_random_features(numerical, categorical):\n",
        "    # Генерация случайного выбора для числовых фич\n",
        "    num_sample = random.choice([None, random.sample(numerical, random.randint(1, len(numerical)))])\n",
        "\n",
        "    # Генерация случайного выбора для категориальных фич\n",
        "    cat_sample = random.choice([None, random.sample(categorical, random.randint(1, len(categorical)))])\n",
        "\n",
        "    # Если не выбрана ни одна фича, возвращаем None для обоих категорий\n",
        "    if num_sample is None and cat_sample is None:\n",
        "        return {'numerical': None, 'categorical': None}\n",
        "\n",
        "    return {'numerical': num_sample, 'categorical': cat_sample}"
      ],
      "metadata": {
        "id": "FMwNg0zXbpgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features =  generate_random_features(numerical, categorical)\n",
        "num, cat = features['numerical'], features['categorical']\n",
        "embeds = {}\n",
        "if cat is not None:\n",
        "  for j in cat:\n",
        "    random_dim = np.random.choice([32, 16, 8, 4])\n",
        "    # parameters[i][f'emb_dim_{j}'] = random_dim\n",
        "    embeds.update({j: {\"in\": emb_values[j], \"out\": random_dim}})"
      ],
      "metadata": {
        "id": "ESwVyRKq50Vo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_size = len(num) if num!= None else 0\n",
        "emb_size = sum([val['out'] for val in embeds.values()])"
      ],
      "metadata": {
        "id": "I2MiKEdw6e1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import json\n",
        "\n",
        "def save_res(dct, path):\n",
        "    # Сохранение в бинарном формате с использованием pickle\n",
        "    with open(path + '.pkl', 'wb') as handle:\n",
        "        pickle.dump(dct, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "    # # Сохранение в читаемом формате (JSON) в .txt\n",
        "    # with open(path + '.txt', 'w', encoding='utf-8') as handle:\n",
        "    #     json.dump(dct, handle, indent=4, ensure_ascii=False)\n",
        "\n",
        "    # Сохранение в читаемом формате (Python-код) в .py\n",
        "    with open(path + '.py', 'w', encoding='utf-8') as handle:\n",
        "        handle.write(f\"data = {repr(dct)}\")"
      ],
      "metadata": {
        "id": "yR_Q912M_521"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# parameters\n",
        "PATH = '/content/drive/MyDrive/PTLS/data_ensemble_age_group/train_params'\n",
        "with open(PATH + '.pkl', 'rb') as handle:\n",
        "   parameters = pickle.load(handle)"
      ],
      "metadata": {
        "id": "A-9BuVbDCZ_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(NUM_EXP):\n",
        "    while True:\n",
        "\n",
        "      try:\n",
        "\n",
        "        parameters[i] = {}\n",
        "\n",
        "        all_features = [id_col, date_col]\n",
        "        num, cat = None, None\n",
        "        while num== None and cat==None:\n",
        "          features =  generate_random_features(numerical, categorical)\n",
        "          num, cat = features['numerical'], features['categorical']\n",
        "\n",
        "\n",
        "        parameters[i]['num'], parameters[i]['cat'] = num, cat\n",
        "\n",
        "        if cat is not None:\n",
        "          all_features +=cat\n",
        "        if num is not None:\n",
        "          all_features +=num\n",
        "        all_features = list(set(all_features))\n",
        "\n",
        "        data = source_data[all_features]\n",
        "\n",
        "        source_preprocessor = PandasDataPreprocessor(\n",
        "          col_id=id_col,\n",
        "          col_event_time=date_col,\n",
        "          event_time_transformation=\"none\",\n",
        "          cols_numerical=num,\n",
        "          cols_category = cat,\n",
        "          return_records=True,\n",
        "        )\n",
        "\n",
        "        dataset = source_preprocessor.fit_transform(data)\n",
        "        dataset = sorted(dataset, key=lambda x: x[id_col])\n",
        "\n",
        "\n",
        "        train, test = train_test_split(dataset, test_size=0.2, random_state=42)\n",
        "\n",
        "        # все кат фичи переводим в размерность рандомную из списка\n",
        "\n",
        "        embeds = {}\n",
        "        if cat is not None:\n",
        "          for j in cat:\n",
        "            random_dim = np.random.choice([32, 16, 8, 4])\n",
        "            parameters[i][f'emb_dim_{j}'] = random_dim\n",
        "            embeds.update({j: {\"in\": emb_values[j], \"out\": random_dim}})\n",
        "\n",
        "\n",
        "        num_size = len(num) if num!= None else 0\n",
        "        emb_size = sum([val['out'] for val in embeds.values()])\n",
        "        rnn_inp_size = num_size + emb_size\n",
        "\n",
        "        random_noise = np.random.uniform(0, 0.1)\n",
        "        parameters[i]['random_noise'] = random_noise\n",
        "        random_linear_projection = np.random.choice([0, 32, 64, 128, 256])\n",
        "        parameters[i]['random_linear_projection'] = random_linear_projection\n",
        "\n",
        "\n",
        "        trx_encoder_params = dict(\n",
        "            embeddings_noise = random_noise,\n",
        "            linear_projection_size = random_linear_projection,\n",
        "            embeddings = embeds,\n",
        "            numeric_values = {i:'identity' for i in num} if num is not None else None,\n",
        "        )\n",
        "\n",
        "\n",
        "        random_type = np.random.choice(['lstm', 'gru'])\n",
        "        parameters[i]['random_type'] = random_type\n",
        "\n",
        "\n",
        "        seq_encoder = RnnSeqEncoder(\n",
        "            trx_encoder=TrxEncoder(**trx_encoder_params),\n",
        "            input_size = random_linear_projection if random_linear_projection is not None else rnn_inp_size,\n",
        "            hidden_size=256,\n",
        "            type=random_type,\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "        random_lr = float(np.random.choice([0.001, 0.005, 0.01, 0.0003, 0.0001]))\n",
        "        parameters[i]['random_lr'] = random_lr\n",
        "        random_margin = float(np.random.choice(np.arange(0.1, 1.1, 0.1)))\n",
        "        parameters[i]['random_margin'] = random_margin\n",
        "        random_neg_count = int(np.random.choice(np.arange(1, 4, 1)))\n",
        "        parameters[i]['random_neg_count'] = random_neg_count\n",
        "\n",
        "\n",
        "        loss = ContrastiveLoss(margin=random_margin, sampling_strategy=HardNegativePairSelector(neg_count=random_neg_count))\n",
        "        model = CoLESModule(\n",
        "            seq_encoder=seq_encoder,\n",
        "            optimizer_partial=partial(torch.optim.Adam, lr = random_lr),\n",
        "            lr_scheduler_partial=partial(\n",
        "                torch.optim.lr_scheduler.StepLR, step_size=30, gamma=0.9\n",
        "            ),\n",
        "        )\n",
        "\n",
        "        random_split_count = np.random.choice(np.arange(1, 5, 1))\n",
        "        parameters[i]['random_split_count'] = random_split_count\n",
        "        random_cnt_min = np.random.choice(np.arange(10, 50, 5))\n",
        "        parameters[i]['random_cnt_min'] = random_cnt_min\n",
        "        random_cnt_max = np.random.choice(np.arange(random_cnt_min+5, 250, 5))\n",
        "        parameters[i]['random_cnt_max'] = random_cnt_max\n",
        "\n",
        "\n",
        "        train_dl = PtlsDataModule(\n",
        "            train_data=ColesDataset(\n",
        "                MemoryMapDataset(\n",
        "                    data=train,\n",
        "                    i_filters=[SeqLenFilter(min_seq_len=25)],\n",
        "                ),\n",
        "                splitter=SampleSlices(\n",
        "                    split_count=random_split_count,\n",
        "                    cnt_min=random_cnt_min,\n",
        "                    cnt_max=random_cnt_max,\n",
        "                ),\n",
        "            ),\n",
        "            train_num_workers=16,\n",
        "            train_batch_size=256,\n",
        "        )\n",
        "\n",
        "\n",
        "        random_max_epochs = int(np.random.choice(np.arange(5, 18, 1)))\n",
        "        parameters[i]['random_max_epochs'] = random_max_epochs\n",
        "\n",
        "        trainer = pl.Trainer(\n",
        "            max_epochs=random_max_epochs,\n",
        "            accelerator=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "            enable_progress_bar=False,\n",
        "        )\n",
        "\n",
        "        trainer.fit(model, train_dl)\n",
        "        print(trainer.logged_metrics)\n",
        "        parameters[i]['logged_metrics'] = trainer.logged_metrics\n",
        "\n",
        "        train_dl = inference_data_loader(train, num_workers=0, batch_size=256)\n",
        "        train_embeds = torch.vstack(trainer.predict(model, train_dl, ))\n",
        "\n",
        "        test_dl = inference_data_loader(test, num_workers=0, batch_size=256)\n",
        "        test_embeds = torch.vstack(trainer.predict(model, test_dl))\n",
        "\n",
        "\n",
        "        train_df = pd.DataFrame(data=train_embeds, columns=[f\"embed_{i}\" for i in range(train_embeds.shape[1])])\n",
        "        train_df[\"client_id\"] = [x[\"client_id\"] for x in train]\n",
        "        train_df = train_df.merge(df_target, how=\"left\", on=\"client_id\")\n",
        "\n",
        "        test_df = pd.DataFrame(data=test_embeds, columns=[f\"embed_{i}\" for i in range(test_embeds.shape[1])])\n",
        "        test_df[\"client_id\"] = [x[\"client_id\"] for x in test]\n",
        "        test_df = test_df.merge(df_target, how=\"left\", on=\"client_id\")\n",
        "\n",
        "\n",
        "        train_df.to_csv(f'/content/drive/MyDrive/PTLS/data_ensemble_age_group/train_df{i}.csv')\n",
        "        test_df.to_csv(f'/content/drive/MyDrive/PTLS/data_ensemble_age_group/test_df{i}.csv')\n",
        "        save_res(parameters, PATH)\n",
        "        print(parameters[i])\n",
        "        break\n",
        "\n",
        "      except Exception as e:\n",
        "        print(f\"Ошибка на итерации {i}: {e}\")\n",
        "        continue  # Повторяем итерацию с тем же i"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PcXN9uuZSNe",
        "outputId": "037d9421-6d2c-4092-ac32-3bbb0f669f54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type            | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | _loss              | ContrastiveLoss | 0      | train\n",
            "1 | _seq_encoder       | RnnSeqEncoder   | 247 K  | train\n",
            "2 | _validation_metric | BatchRecallTopK | 0      | train\n",
            "3 | _head              | Head            | 0      | train\n",
            "---------------------------------------------------------------\n",
            "247 K     Trainable params\n",
            "0         Non-trainable params\n",
            "247 K     Total params\n",
            "0.990     Total estimated model params size (MB)\n",
            "18        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=12` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': tensor(260.4991), 'seq_len': tensor(100.8411)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num': ['amount_rur'], 'cat': ['trans_date'], 'emb_dim_trans_date': 32, 'random_noise': 0.07227087102608425, 'random_linear_projection': 32, 'random_type': 'gru', 'random_lr': 0.005, 'random_margin': 0.30000000000000004, 'random_neg_count': 3, 'random_split_count': 4, 'random_cnt_min': 40, 'random_cnt_max': 160, 'random_max_epochs': 12, 'logged_metrics': {'loss': tensor(260.4991), 'seq_len': tensor(100.8411)}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type            | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | _loss              | ContrastiveLoss | 0      | train\n",
            "1 | _seq_encoder       | RnnSeqEncoder   | 223 K  | train\n",
            "2 | _validation_metric | BatchRecallTopK | 0      | train\n",
            "3 | _head              | Head            | 0      | train\n",
            "---------------------------------------------------------------\n",
            "223 K     Trainable params\n",
            "0         Non-trainable params\n",
            "223 K     Total params\n",
            "0.892     Total estimated model params size (MB)\n",
            "16        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=16` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': tensor(0.6172), 'seq_len': tensor(88.8073)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num': ['amount_rur'], 'cat': None, 'random_noise': 0.04507372261712233, 'random_linear_projection': 32, 'random_type': 'gru', 'random_lr': 0.0001, 'random_margin': 0.6, 'random_neg_count': 3, 'random_split_count': 1, 'random_cnt_min': 20, 'random_cnt_max': 160, 'random_max_epochs': 16, 'logged_metrics': {'loss': tensor(0.6172), 'seq_len': tensor(88.8073)}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type            | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | _loss              | ContrastiveLoss | 0      | train\n",
            "1 | _seq_encoder       | RnnSeqEncoder   | 329 K  | train\n",
            "2 | _validation_metric | BatchRecallTopK | 0      | train\n",
            "3 | _head              | Head            | 0      | train\n",
            "---------------------------------------------------------------\n",
            "329 K     Trainable params\n",
            "0         Non-trainable params\n",
            "329 K     Total params\n",
            "1.319     Total estimated model params size (MB)\n",
            "20        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=11` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': tensor(171.2316), 'seq_len': tensor(94.5729)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num': ['amount_rur'], 'cat': ['trans_date', 'small_group'], 'emb_dim_trans_date': 32, 'emb_dim_small_group': 16, 'random_noise': 0.05948739413829332, 'random_linear_projection': 128, 'random_type': 'gru', 'random_lr': 0.005, 'random_margin': 0.5, 'random_neg_count': 1, 'random_split_count': 4, 'random_cnt_min': 45, 'random_cnt_max': 145, 'random_max_epochs': 11, 'logged_metrics': {'loss': tensor(171.2316), 'seq_len': tensor(94.5729)}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type            | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | _loss              | ContrastiveLoss | 0      | train\n",
            "1 | _seq_encoder       | RnnSeqEncoder   | 303 K  | train\n",
            "2 | _validation_metric | BatchRecallTopK | 0      | train\n",
            "3 | _head              | Head            | 0      | train\n",
            "---------------------------------------------------------------\n",
            "303 K     Trainable params\n",
            "0         Non-trainable params\n",
            "303 K     Total params\n",
            "1.212     Total estimated model params size (MB)\n",
            "20        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=13` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': tensor(0.), 'seq_len': tensor(68.7240)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num': ['amount_rur'], 'cat': ['small_group', 'trans_date'], 'emb_dim_small_group': 8, 'emb_dim_trans_date': 4, 'random_noise': 0.052023455791215104, 'random_linear_projection': 128, 'random_type': 'gru', 'random_lr': 0.005, 'random_margin': 0.7000000000000001, 'random_neg_count': 3, 'random_split_count': 1, 'random_cnt_min': 25, 'random_cnt_max': 110, 'random_max_epochs': 13, 'logged_metrics': {'loss': tensor(0.), 'seq_len': tensor(68.7240)}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type            | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | _loss              | ContrastiveLoss | 0      | train\n",
            "1 | _seq_encoder       | RnnSeqEncoder   | 395 K  | train\n",
            "2 | _validation_metric | BatchRecallTopK | 0      | train\n",
            "3 | _head              | Head            | 0      | train\n",
            "---------------------------------------------------------------\n",
            "395 K     Trainable params\n",
            "0         Non-trainable params\n",
            "395 K     Total params\n",
            "1.583     Total estimated model params size (MB)\n",
            "16        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=6` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': tensor(0.2866), 'seq_len': tensor(114.0938)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num': ['amount_rur'], 'cat': None, 'random_noise': 0.03580508181995499, 'random_linear_projection': 128, 'random_type': 'lstm', 'random_lr': 0.0001, 'random_margin': 1.0, 'random_neg_count': 3, 'random_split_count': 1, 'random_cnt_min': 45, 'random_cnt_max': 195, 'random_max_epochs': 6, 'logged_metrics': {'loss': tensor(0.2866), 'seq_len': tensor(114.0938)}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type            | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | _loss              | ContrastiveLoss | 0      | train\n",
            "1 | _seq_encoder       | RnnSeqEncoder   | 227 K  | train\n",
            "2 | _validation_metric | BatchRecallTopK | 0      | train\n",
            "3 | _head              | Head            | 0      | train\n",
            "---------------------------------------------------------------\n",
            "227 K     Trainable params\n",
            "0         Non-trainable params\n",
            "227 K     Total params\n",
            "0.912     Total estimated model params size (MB)\n",
            "20        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=5` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': tensor(39.6562), 'seq_len': tensor(103.5339)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num': ['amount_rur'], 'cat': ['trans_date', 'small_group'], 'emb_dim_trans_date': 4, 'emb_dim_small_group': 8, 'random_noise': 0.09158047655341472, 'random_linear_projection': 32, 'random_type': 'gru', 'random_lr': 0.01, 'random_margin': 0.6, 'random_neg_count': 3, 'random_split_count': 2, 'random_cnt_min': 10, 'random_cnt_max': 190, 'random_max_epochs': 5, 'logged_metrics': {'loss': tensor(39.6562), 'seq_len': tensor(103.5339)}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type            | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | _loss              | ContrastiveLoss | 0      | train\n",
            "1 | _seq_encoder       | RnnSeqEncoder   | 254 K  | train\n",
            "2 | _validation_metric | BatchRecallTopK | 0      | train\n",
            "3 | _head              | Head            | 0      | train\n",
            "---------------------------------------------------------------\n",
            "254 K     Trainable params\n",
            "0         Non-trainable params\n",
            "254 K     Total params\n",
            "1.016     Total estimated model params size (MB)\n",
            "18        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=17` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': tensor(67.6900), 'seq_len': tensor(37.5547)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num': ['amount_rur'], 'cat': ['trans_date'], 'emb_dim_trans_date': 8, 'random_noise': 0.012838812550055935, 'random_linear_projection': 64, 'random_type': 'gru', 'random_lr': 0.0001, 'random_margin': 0.7000000000000001, 'random_neg_count': 3, 'random_split_count': 2, 'random_cnt_min': 30, 'random_cnt_max': 45, 'random_max_epochs': 17, 'logged_metrics': {'loss': tensor(67.6900), 'seq_len': tensor(37.5547)}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type            | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | _loss              | ContrastiveLoss | 0      | train\n",
            "1 | _seq_encoder       | RnnSeqEncoder   | 299 K  | train\n",
            "2 | _validation_metric | BatchRecallTopK | 0      | train\n",
            "3 | _head              | Head            | 0      | train\n",
            "---------------------------------------------------------------\n",
            "299 K     Trainable params\n",
            "0         Non-trainable params\n",
            "299 K     Total params\n",
            "1.196     Total estimated model params size (MB)\n",
            "15        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=14` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': tensor(59.3112), 'seq_len': tensor(36.8984)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num': None, 'cat': ['small_group'], 'emb_dim_small_group': 8, 'random_noise': 0.07281079865633451, 'random_linear_projection': 32, 'random_type': 'lstm', 'random_lr': 0.0003, 'random_margin': 0.30000000000000004, 'random_neg_count': 3, 'random_split_count': 2, 'random_cnt_min': 20, 'random_cnt_max': 55, 'random_max_epochs': 14, 'logged_metrics': {'loss': tensor(59.3112), 'seq_len': tensor(36.8984)}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ошибка на итерации 42: cuDNN error: CUDNN_STATUS_BAD_PARAM\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type            | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | _loss              | ContrastiveLoss | 0      | train\n",
            "1 | _seq_encoder       | RnnSeqEncoder   | 324 K  | train\n",
            "2 | _validation_metric | BatchRecallTopK | 0      | train\n",
            "3 | _head              | Head            | 0      | train\n",
            "---------------------------------------------------------------\n",
            "324 K     Trainable params\n",
            "0         Non-trainable params\n",
            "324 K     Total params\n",
            "1.298     Total estimated model params size (MB)\n",
            "18        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=7` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': tensor(0.), 'seq_len': tensor(83.5469)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num': ['amount_rur'], 'cat': ['trans_date'], 'emb_dim_trans_date': 32, 'random_noise': 0.006681029235071235, 'random_linear_projection': 128, 'random_type': 'gru', 'random_lr': 0.01, 'random_margin': 0.9, 'random_neg_count': 3, 'random_split_count': 1, 'random_cnt_min': 15, 'random_cnt_max': 150, 'random_max_epochs': 7, 'logged_metrics': {'loss': tensor(0.), 'seq_len': tensor(83.5469)}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type            | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | _loss              | ContrastiveLoss | 0      | train\n",
            "1 | _seq_encoder       | RnnSeqEncoder   | 334 K  | train\n",
            "2 | _validation_metric | BatchRecallTopK | 0      | train\n",
            "3 | _head              | Head            | 0      | train\n",
            "---------------------------------------------------------------\n",
            "334 K     Trainable params\n",
            "0         Non-trainable params\n",
            "334 K     Total params\n",
            "1.337     Total estimated model params size (MB)\n",
            "17        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=17` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': tensor(48.7477), 'seq_len': tensor(80.0052)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num': None, 'cat': ['small_group', 'trans_date'], 'emb_dim_small_group': 4, 'emb_dim_trans_date': 4, 'random_noise': 0.00667060554918606, 'random_linear_projection': 64, 'random_type': 'lstm', 'random_lr': 0.001, 'random_margin': 0.7000000000000001, 'random_neg_count': 2, 'random_split_count': 2, 'random_cnt_min': 10, 'random_cnt_max': 155, 'random_max_epochs': 17, 'logged_metrics': {'loss': tensor(48.7477), 'seq_len': tensor(80.0052)}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type            | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | _loss              | ContrastiveLoss | 0      | train\n",
            "1 | _seq_encoder       | RnnSeqEncoder   | 296 K  | train\n",
            "2 | _validation_metric | BatchRecallTopK | 0      | train\n",
            "3 | _head              | Head            | 0      | train\n",
            "---------------------------------------------------------------\n",
            "296 K     Trainable params\n",
            "0         Non-trainable params\n",
            "296 K     Total params\n",
            "1.188     Total estimated model params size (MB)\n",
            "16        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=5` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': tensor(178.8804), 'seq_len': tensor(47.6198)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num': ['amount_rur'], 'cat': None, 'random_noise': 0.015112502450200427, 'random_linear_projection': 128, 'random_type': 'gru', 'random_lr': 0.001, 'random_margin': 0.9, 'random_neg_count': 1, 'random_split_count': 3, 'random_cnt_min': 40, 'random_cnt_max': 55, 'random_max_epochs': 5, 'logged_metrics': {'loss': tensor(178.8804), 'seq_len': tensor(47.6198)}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type            | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | _loss              | ContrastiveLoss | 0      | train\n",
            "1 | _seq_encoder       | RnnSeqEncoder   | 337 K  | train\n",
            "2 | _validation_metric | BatchRecallTopK | 0      | train\n",
            "3 | _head              | Head            | 0      | train\n",
            "---------------------------------------------------------------\n",
            "337 K     Trainable params\n",
            "0         Non-trainable params\n",
            "337 K     Total params\n",
            "1.350     Total estimated model params size (MB)\n",
            "20        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=13` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': tensor(45.4347), 'seq_len': tensor(37.7604)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num': ['amount_rur'], 'cat': ['small_group', 'trans_date'], 'emb_dim_small_group': 4, 'emb_dim_trans_date': 8, 'random_noise': 0.0196624306864452, 'random_linear_projection': 64, 'random_type': 'lstm', 'random_lr': 0.005, 'random_margin': 1.0, 'random_neg_count': 2, 'random_split_count': 2, 'random_cnt_min': 20, 'random_cnt_max': 55, 'random_max_epochs': 13, 'logged_metrics': {'loss': tensor(45.4347), 'seq_len': tensor(37.7604)}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ошибка на итерации 46: cuDNN error: CUDNN_STATUS_BAD_PARAM\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type            | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | _loss              | ContrastiveLoss | 0      | train\n",
            "1 | _seq_encoder       | RnnSeqEncoder   | 527 K  | train\n",
            "2 | _validation_metric | BatchRecallTopK | 0      | train\n",
            "3 | _head              | Head            | 0      | train\n",
            "---------------------------------------------------------------\n",
            "527 K     Trainable params\n",
            "0         Non-trainable params\n",
            "527 K     Total params\n",
            "2.108     Total estimated model params size (MB)\n",
            "16        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=9` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': tensor(78.2523), 'seq_len': tensor(50.6953)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num': ['amount_rur'], 'cat': None, 'random_noise': 0.01709785423066165, 'random_linear_projection': 256, 'random_type': 'lstm', 'random_lr': 0.0003, 'random_margin': 0.8, 'random_neg_count': 3, 'random_split_count': 2, 'random_cnt_min': 10, 'random_cnt_max': 90, 'random_max_epochs': 9, 'logged_metrics': {'loss': tensor(78.2523), 'seq_len': tensor(50.6953)}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type            | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | _loss              | ContrastiveLoss | 0      | train\n",
            "1 | _seq_encoder       | RnnSeqEncoder   | 395 K  | train\n",
            "2 | _validation_metric | BatchRecallTopK | 0      | train\n",
            "3 | _head              | Head            | 0      | train\n",
            "---------------------------------------------------------------\n",
            "395 K     Trainable params\n",
            "0         Non-trainable params\n",
            "395 K     Total params\n",
            "1.582     Total estimated model params size (MB)\n",
            "16        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=9` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': tensor(221.7676), 'seq_len': tensor(47.2361)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num': ['amount_rur'], 'cat': None, 'random_noise': 0.08906375696596071, 'random_linear_projection': 256, 'random_type': 'gru', 'random_lr': 0.0001, 'random_margin': 0.8, 'random_neg_count': 2, 'random_split_count': 3, 'random_cnt_min': 25, 'random_cnt_max': 70, 'random_max_epochs': 9, 'logged_metrics': {'loss': tensor(221.7676), 'seq_len': tensor(47.2361)}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type            | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | _loss              | ContrastiveLoss | 0      | train\n",
            "1 | _seq_encoder       | RnnSeqEncoder   | 398 K  | train\n",
            "2 | _validation_metric | BatchRecallTopK | 0      | train\n",
            "3 | _head              | Head            | 0      | train\n",
            "---------------------------------------------------------------\n",
            "398 K     Trainable params\n",
            "0         Non-trainable params\n",
            "398 K     Total params\n",
            "1.596     Total estimated model params size (MB)\n",
            "15        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=10` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': tensor(224.0484), 'seq_len': tensor(76.5182)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num': None, 'cat': ['small_group'], 'emb_dim_small_group': 8, 'random_noise': 0.005321638203530455, 'random_linear_projection': 256, 'random_type': 'gru', 'random_lr': 0.0003, 'random_margin': 0.6, 'random_neg_count': 2, 'random_split_count': 4, 'random_cnt_min': 20, 'random_cnt_max': 135, 'random_max_epochs': 10, 'logged_metrics': {'loss': tensor(224.0484), 'seq_len': tensor(76.5182)}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type            | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | _loss              | ContrastiveLoss | 0      | train\n",
            "1 | _seq_encoder       | RnnSeqEncoder   | 425 K  | train\n",
            "2 | _validation_metric | BatchRecallTopK | 0      | train\n",
            "3 | _head              | Head            | 0      | train\n",
            "---------------------------------------------------------------\n",
            "425 K     Trainable params\n",
            "0         Non-trainable params\n",
            "425 K     Total params\n",
            "1.703     Total estimated model params size (MB)\n",
            "17        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=5` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': tensor(33.7111), 'seq_len': tensor(131.5312)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num': None, 'cat': ['trans_date', 'small_group'], 'emb_dim_trans_date': 16, 'emb_dim_small_group': 32, 'random_noise': 0.052714712604709224, 'random_linear_projection': 256, 'random_type': 'gru', 'random_lr': 0.005, 'random_margin': 1.0, 'random_neg_count': 2, 'random_split_count': 2, 'random_cnt_min': 15, 'random_cnt_max': 240, 'random_max_epochs': 5, 'logged_metrics': {'loss': tensor(33.7111), 'seq_len': tensor(131.5312)}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type            | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | _loss              | ContrastiveLoss | 0      | train\n",
            "1 | _seq_encoder       | RnnSeqEncoder   | 403 K  | train\n",
            "2 | _validation_metric | BatchRecallTopK | 0      | train\n",
            "3 | _head              | Head            | 0      | train\n",
            "---------------------------------------------------------------\n",
            "403 K     Trainable params\n",
            "0         Non-trainable params\n",
            "403 K     Total params\n",
            "1.613     Total estimated model params size (MB)\n",
            "20        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=6` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': tensor(0.), 'seq_len': tensor(62.8073)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num': ['amount_rur'], 'cat': ['trans_date', 'small_group'], 'emb_dim_trans_date': 4, 'emb_dim_small_group': 8, 'random_noise': 0.0452618028483405, 'random_linear_projection': 256, 'random_type': 'gru', 'random_lr': 0.005, 'random_margin': 0.8, 'random_neg_count': 2, 'random_split_count': 1, 'random_cnt_min': 10, 'random_cnt_max': 115, 'random_max_epochs': 6, 'logged_metrics': {'loss': tensor(0.), 'seq_len': tensor(62.8073)}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type            | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | _loss              | ContrastiveLoss | 0      | train\n",
            "1 | _seq_encoder       | RnnSeqEncoder   | 223 K  | train\n",
            "2 | _validation_metric | BatchRecallTopK | 0      | train\n",
            "3 | _head              | Head            | 0      | train\n",
            "---------------------------------------------------------------\n",
            "223 K     Trainable params\n",
            "0         Non-trainable params\n",
            "223 K     Total params\n",
            "0.892     Total estimated model params size (MB)\n",
            "16        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=10` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': tensor(285.9720), 'seq_len': tensor(93.1784)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num': ['amount_rur'], 'cat': None, 'random_noise': 0.005402033624513869, 'random_linear_projection': 32, 'random_type': 'gru', 'random_lr': 0.01, 'random_margin': 0.7000000000000001, 'random_neg_count': 1, 'random_split_count': 4, 'random_cnt_min': 10, 'random_cnt_max': 175, 'random_max_epochs': 10, 'logged_metrics': {'loss': tensor(285.9720), 'seq_len': tensor(93.1784)}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ошибка на итерации 52: cuDNN error: CUDNN_STATUS_BAD_PARAM\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type            | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | _loss              | ContrastiveLoss | 0      | train\n",
            "1 | _seq_encoder       | RnnSeqEncoder   | 338 K  | train\n",
            "2 | _validation_metric | BatchRecallTopK | 0      | train\n",
            "3 | _head              | Head            | 0      | train\n",
            "---------------------------------------------------------------\n",
            "338 K     Trainable params\n",
            "0         Non-trainable params\n",
            "338 K     Total params\n",
            "1.354     Total estimated model params size (MB)\n",
            "15        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=5` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': tensor(146.2114), 'seq_len': tensor(12.4635)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num': None, 'cat': ['small_group'], 'emb_dim_small_group': 32, 'random_noise': 0.07947433938770991, 'random_linear_projection': 64, 'random_type': 'lstm', 'random_lr': 0.005, 'random_margin': 0.2, 'random_neg_count': 1, 'random_split_count': 3, 'random_cnt_min': 10, 'random_cnt_max': 15, 'random_max_epochs': 5, 'logged_metrics': {'loss': tensor(146.2114), 'seq_len': tensor(12.4635)}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type            | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | _loss              | ContrastiveLoss | 0      | train\n",
            "1 | _seq_encoder       | RnnSeqEncoder   | 330 K  | train\n",
            "2 | _validation_metric | BatchRecallTopK | 0      | train\n",
            "3 | _head              | Head            | 0      | train\n",
            "---------------------------------------------------------------\n",
            "330 K     Trainable params\n",
            "0         Non-trainable params\n",
            "330 K     Total params\n",
            "1.320     Total estimated model params size (MB)\n",
            "16        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=6` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': tensor(446.3193), 'seq_len': tensor(79.8034)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num': ['amount_rur'], 'cat': None, 'random_noise': 0.09068017942589993, 'random_linear_projection': 64, 'random_type': 'lstm', 'random_lr': 0.0001, 'random_margin': 0.6, 'random_neg_count': 1, 'random_split_count': 4, 'random_cnt_min': 35, 'random_cnt_max': 125, 'random_max_epochs': 6, 'logged_metrics': {'loss': tensor(446.3193), 'seq_len': tensor(79.8034)}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type            | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | _loss              | ContrastiveLoss | 0      | train\n",
            "1 | _seq_encoder       | RnnSeqEncoder   | 395 K  | train\n",
            "2 | _validation_metric | BatchRecallTopK | 0      | train\n",
            "3 | _head              | Head            | 0      | train\n",
            "---------------------------------------------------------------\n",
            "395 K     Trainable params\n",
            "0         Non-trainable params\n",
            "395 K     Total params\n",
            "1.582     Total estimated model params size (MB)\n",
            "16        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=17` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': tensor(73.7927), 'seq_len': tensor(134.7917)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num': ['amount_rur'], 'cat': None, 'random_noise': 0.004573661043309696, 'random_linear_projection': 256, 'random_type': 'gru', 'random_lr': 0.01, 'random_margin': 1.0, 'random_neg_count': 3, 'random_split_count': 2, 'random_cnt_min': 45, 'random_cnt_max': 225, 'random_max_epochs': 17, 'logged_metrics': {'loss': tensor(73.7927), 'seq_len': tensor(134.7917)}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ошибка на итерации 55: cuDNN error: CUDNN_STATUS_BAD_PARAM\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type            | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | _loss              | ContrastiveLoss | 0      | train\n",
            "1 | _seq_encoder       | RnnSeqEncoder   | 236 K  | train\n",
            "2 | _validation_metric | BatchRecallTopK | 0      | train\n",
            "3 | _head              | Head            | 0      | train\n",
            "---------------------------------------------------------------\n",
            "236 K     Trainable params\n",
            "0         Non-trainable params\n",
            "236 K     Total params\n",
            "0.945     Total estimated model params size (MB)\n",
            "20        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=17` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': tensor(153.7287), 'seq_len': tensor(129.4675)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num': ['amount_rur'], 'cat': ['trans_date', 'small_group'], 'emb_dim_trans_date': 16, 'emb_dim_small_group': 4, 'random_noise': 0.011645479073830511, 'random_linear_projection': 32, 'random_type': 'gru', 'random_lr': 0.005, 'random_margin': 0.1, 'random_neg_count': 3, 'random_split_count': 4, 'random_cnt_min': 40, 'random_cnt_max': 215, 'random_max_epochs': 17, 'logged_metrics': {'loss': tensor(153.7287), 'seq_len': tensor(129.4675)}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type            | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | _loss              | ContrastiveLoss | 0      | train\n",
            "1 | _seq_encoder       | RnnSeqEncoder   | 398 K  | train\n",
            "2 | _validation_metric | BatchRecallTopK | 0      | train\n",
            "3 | _head              | Head            | 0      | train\n",
            "---------------------------------------------------------------\n",
            "398 K     Trainable params\n",
            "0         Non-trainable params\n",
            "398 K     Total params\n",
            "1.593     Total estimated model params size (MB)\n",
            "15        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=8` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': tensor(128.5293), 'seq_len': tensor(57.3038)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num': None, 'cat': ['small_group'], 'emb_dim_small_group': 8, 'random_noise': 0.05261890723714418, 'random_linear_projection': 128, 'random_type': 'lstm', 'random_lr': 0.01, 'random_margin': 0.6, 'random_neg_count': 3, 'random_split_count': 3, 'random_cnt_min': 10, 'random_cnt_max': 105, 'random_max_epochs': 8, 'logged_metrics': {'loss': tensor(128.5293), 'seq_len': tensor(57.3038)}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type            | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | _loss              | ContrastiveLoss | 0      | train\n",
            "1 | _seq_encoder       | RnnSeqEncoder   | 541 K  | train\n",
            "2 | _validation_metric | BatchRecallTopK | 0      | train\n",
            "3 | _head              | Head            | 0      | train\n",
            "---------------------------------------------------------------\n",
            "541 K     Trainable params\n",
            "0         Non-trainable params\n",
            "541 K     Total params\n",
            "2.166     Total estimated model params size (MB)\n",
            "15        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=17` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': tensor(46.0454), 'seq_len': tensor(111.8958)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num': None, 'cat': ['small_group'], 'emb_dim_small_group': 32, 'random_noise': 0.08774903534085444, 'random_linear_projection': 256, 'random_type': 'lstm', 'random_lr': 0.0001, 'random_margin': 0.9, 'random_neg_count': 2, 'random_split_count': 2, 'random_cnt_min': 30, 'random_cnt_max': 205, 'random_max_epochs': 17, 'logged_metrics': {'loss': tensor(46.0454), 'seq_len': tensor(111.8958)}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type            | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | _loss              | ContrastiveLoss | 0      | train\n",
            "1 | _seq_encoder       | RnnSeqEncoder   | 395 K  | train\n",
            "2 | _validation_metric | BatchRecallTopK | 0      | train\n",
            "3 | _head              | Head            | 0      | train\n",
            "---------------------------------------------------------------\n",
            "395 K     Trainable params\n",
            "0         Non-trainable params\n",
            "395 K     Total params\n",
            "1.582     Total estimated model params size (MB)\n",
            "16        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=14` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': tensor(164.0139), 'seq_len': tensor(27.5399)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num': ['amount_rur'], 'cat': None, 'random_noise': 0.013437971720995347, 'random_linear_projection': 256, 'random_type': 'gru', 'random_lr': 0.001, 'random_margin': 0.1, 'random_neg_count': 2, 'random_split_count': 3, 'random_cnt_min': 15, 'random_cnt_max': 40, 'random_max_epochs': 14, 'logged_metrics': {'loss': tensor(164.0139), 'seq_len': tensor(27.5399)}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type            | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | _loss              | ContrastiveLoss | 0      | train\n",
            "1 | _seq_encoder       | RnnSeqEncoder   | 260 K  | train\n",
            "2 | _validation_metric | BatchRecallTopK | 0      | train\n",
            "3 | _head              | Head            | 0      | train\n",
            "---------------------------------------------------------------\n",
            "260 K     Trainable params\n",
            "0         Non-trainable params\n",
            "260 K     Total params\n",
            "1.041     Total estimated model params size (MB)\n",
            "15        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=5` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': tensor(0.0262), 'seq_len': tensor(82.7865)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num': None, 'cat': ['trans_date'], 'emb_dim_trans_date': 16, 'random_noise': 0.046104368492933284, 'random_linear_projection': 64, 'random_type': 'gru', 'random_lr': 0.005, 'random_margin': 0.4, 'random_neg_count': 3, 'random_split_count': 1, 'random_cnt_min': 35, 'random_cnt_max': 135, 'random_max_epochs': 5, 'logged_metrics': {'loss': tensor(0.0262), 'seq_len': tensor(82.7865)}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type            | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | _loss              | ContrastiveLoss | 0      | train\n",
            "1 | _seq_encoder       | RnnSeqEncoder   | 528 K  | train\n",
            "2 | _validation_metric | BatchRecallTopK | 0      | train\n",
            "3 | _head              | Head            | 0      | train\n",
            "---------------------------------------------------------------\n",
            "528 K     Trainable params\n",
            "0         Non-trainable params\n",
            "528 K     Total params\n",
            "2.115     Total estimated model params size (MB)\n",
            "15        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=7` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': tensor(52.0621), 'seq_len': tensor(52.3542)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num': None, 'cat': ['small_group'], 'emb_dim_small_group': 4, 'random_noise': 0.033817605141065236, 'random_linear_projection': 256, 'random_type': 'lstm', 'random_lr': 0.005, 'random_margin': 0.8, 'random_neg_count': 3, 'random_split_count': 2, 'random_cnt_min': 15, 'random_cnt_max': 85, 'random_max_epochs': 7, 'logged_metrics': {'loss': tensor(52.0621), 'seq_len': tensor(52.3542)}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ошибка на итерации 61: cuDNN error: CUDNN_STATUS_BAD_PARAM\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type            | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | _loss              | ContrastiveLoss | 0      | train\n",
            "1 | _seq_encoder       | RnnSeqEncoder   | 426 K  | train\n",
            "2 | _validation_metric | BatchRecallTopK | 0      | train\n",
            "3 | _head              | Head            | 0      | train\n",
            "---------------------------------------------------------------\n",
            "426 K     Trainable params\n",
            "0         Non-trainable params\n",
            "426 K     Total params\n",
            "1.707     Total estimated model params size (MB)\n",
            "15        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=15` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': tensor(60.1283), 'seq_len': tensor(87.7292)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num': None, 'cat': ['trans_date'], 'emb_dim_trans_date': 32, 'random_noise': 0.023313037408418915, 'random_linear_projection': 256, 'random_type': 'gru', 'random_lr': 0.01, 'random_margin': 0.2, 'random_neg_count': 2, 'random_split_count': 2, 'random_cnt_min': 15, 'random_cnt_max': 160, 'random_max_epochs': 15, 'logged_metrics': {'loss': tensor(60.1283), 'seq_len': tensor(87.7292)}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type            | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | _loss              | ContrastiveLoss | 0      | train\n",
            "1 | _seq_encoder       | RnnSeqEncoder   | 230 K  | train\n",
            "2 | _validation_metric | BatchRecallTopK | 0      | train\n",
            "3 | _head              | Head            | 0      | train\n",
            "---------------------------------------------------------------\n",
            "230 K     Trainable params\n",
            "0         Non-trainable params\n",
            "230 K     Total params\n",
            "0.922     Total estimated model params size (MB)\n",
            "18        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=14` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': tensor(46.0206), 'seq_len': tensor(115.0651)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num': ['amount_rur'], 'cat': ['small_group'], 'emb_dim_small_group': 32, 'random_noise': 0.08724718726152988, 'random_linear_projection': 32, 'random_type': 'gru', 'random_lr': 0.0003, 'random_margin': 1.0, 'random_neg_count': 2, 'random_split_count': 2, 'random_cnt_min': 45, 'random_cnt_max': 190, 'random_max_epochs': 14, 'logged_metrics': {'loss': tensor(46.0206), 'seq_len': tensor(115.0651)}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type            | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | _loss              | ContrastiveLoss | 0      | train\n",
            "1 | _seq_encoder       | RnnSeqEncoder   | 527 K  | train\n",
            "2 | _validation_metric | BatchRecallTopK | 0      | train\n",
            "3 | _head              | Head            | 0      | train\n",
            "---------------------------------------------------------------\n",
            "527 K     Trainable params\n",
            "0         Non-trainable params\n",
            "527 K     Total params\n",
            "2.108     Total estimated model params size (MB)\n",
            "16        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=10` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': tensor(87.4796), 'seq_len': tensor(129.3281)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num': ['amount_rur'], 'cat': None, 'random_noise': 0.03335123121932493, 'random_linear_projection': 256, 'random_type': 'lstm', 'random_lr': 0.01, 'random_margin': 0.4, 'random_neg_count': 1, 'random_split_count': 2, 'random_cnt_min': 10, 'random_cnt_max': 245, 'random_max_epochs': 10, 'logged_metrics': {'loss': tensor(87.4796), 'seq_len': tensor(129.3281)}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type            | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | _loss              | ContrastiveLoss | 0      | train\n",
            "1 | _seq_encoder       | RnnSeqEncoder   | 333 K  | train\n",
            "2 | _validation_metric | BatchRecallTopK | 0      | train\n",
            "3 | _head              | Head            | 0      | train\n",
            "---------------------------------------------------------------\n",
            "333 K     Trainable params\n",
            "0         Non-trainable params\n",
            "333 K     Total params\n",
            "1.333     Total estimated model params size (MB)\n",
            "18        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=9` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': tensor(57.2123), 'seq_len': tensor(116.0156)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num': ['amount_rur'], 'cat': ['trans_date'], 'emb_dim_trans_date': 4, 'random_noise': 0.01671312917599607, 'random_linear_projection': 64, 'random_type': 'lstm', 'random_lr': 0.01, 'random_margin': 0.1, 'random_neg_count': 3, 'random_split_count': 2, 'random_cnt_min': 20, 'random_cnt_max': 215, 'random_max_epochs': 9, 'logged_metrics': {'loss': tensor(57.2123), 'seq_len': tensor(116.0156)}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type            | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | _loss              | ContrastiveLoss | 0      | train\n",
            "1 | _seq_encoder       | RnnSeqEncoder   | 399 K  | train\n",
            "2 | _validation_metric | BatchRecallTopK | 0      | train\n",
            "3 | _head              | Head            | 0      | train\n",
            "---------------------------------------------------------------\n",
            "399 K     Trainable params\n",
            "0         Non-trainable params\n",
            "399 K     Total params\n",
            "1.597     Total estimated model params size (MB)\n",
            "18        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=9` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': tensor(95.8804), 'seq_len': tensor(104.5573)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num': ['amount_rur'], 'cat': ['small_group'], 'emb_dim_small_group': 8, 'random_noise': 0.019932325448380174, 'random_linear_projection': 256, 'random_type': 'gru', 'random_lr': 0.001, 'random_margin': 0.8, 'random_neg_count': 3, 'random_split_count': 3, 'random_cnt_min': 40, 'random_cnt_max': 165, 'random_max_epochs': 9, 'logged_metrics': {'loss': tensor(95.8804), 'seq_len': tensor(104.5573)}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ошибка на итерации 66: cuDNN error: CUDNN_STATUS_BAD_PARAM\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type            | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | _loss              | ContrastiveLoss | 0      | train\n",
            "1 | _seq_encoder       | RnnSeqEncoder   | 406 K  | train\n",
            "2 | _validation_metric | BatchRecallTopK | 0      | train\n",
            "3 | _head              | Head            | 0      | train\n",
            "---------------------------------------------------------------\n",
            "406 K     Trainable params\n",
            "0         Non-trainable params\n",
            "406 K     Total params\n",
            "1.626     Total estimated model params size (MB)\n",
            "17        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=13` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': tensor(0.0036), 'seq_len': tensor(142.)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num': None, 'cat': ['small_group', 'trans_date'], 'emb_dim_small_group': 16, 'emb_dim_trans_date': 4, 'random_noise': 0.04750287760179152, 'random_linear_projection': 256, 'random_type': 'gru', 'random_lr': 0.0001, 'random_margin': 0.6, 'random_neg_count': 2, 'random_split_count': 1, 'random_cnt_min': 45, 'random_cnt_max': 245, 'random_max_epochs': 13, 'logged_metrics': {'loss': tensor(0.0036), 'seq_len': tensor(142.)}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type            | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | _loss              | ContrastiveLoss | 0      | train\n",
            "1 | _seq_encoder       | RnnSeqEncoder   | 412 K  | train\n",
            "2 | _validation_metric | BatchRecallTopK | 0      | train\n",
            "3 | _head              | Head            | 0      | train\n",
            "---------------------------------------------------------------\n",
            "412 K     Trainable params\n",
            "0         Non-trainable params\n",
            "412 K     Total params\n",
            "1.649     Total estimated model params size (MB)\n",
            "20        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=13` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': tensor(0.), 'seq_len': tensor(68.4427)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num': ['amount_rur'], 'cat': ['trans_date', 'small_group'], 'emb_dim_trans_date': 16, 'emb_dim_small_group': 8, 'random_noise': 0.030265747771266095, 'random_linear_projection': 128, 'random_type': 'lstm', 'random_lr': 0.005, 'random_margin': 0.30000000000000004, 'random_neg_count': 3, 'random_split_count': 1, 'random_cnt_min': 25, 'random_cnt_max': 110, 'random_max_epochs': 13, 'logged_metrics': {'loss': tensor(0.), 'seq_len': tensor(68.4427)}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ошибка на итерации 68: cuDNN error: CUDNN_STATUS_BAD_PARAM\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ошибка на итерации 68: cuDNN error: CUDNN_STATUS_BAD_PARAM\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type            | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | _loss              | ContrastiveLoss | 0      | train\n",
            "1 | _seq_encoder       | RnnSeqEncoder   | 433 K  | train\n",
            "2 | _validation_metric | BatchRecallTopK | 0      | train\n",
            "3 | _head              | Head            | 0      | train\n",
            "---------------------------------------------------------------\n",
            "433 K     Trainable params\n",
            "0         Non-trainable params\n",
            "433 K     Total params\n",
            "1.735     Total estimated model params size (MB)\n",
            "20        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=15` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': tensor(177.4364), 'seq_len': tensor(93.2904)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num': ['amount_rur'], 'cat': ['trans_date', 'small_group'], 'emb_dim_trans_date': 32, 'emb_dim_small_group': 32, 'random_noise': 0.006406120970964291, 'random_linear_projection': 128, 'random_type': 'lstm', 'random_lr': 0.001, 'random_margin': 0.30000000000000004, 'random_neg_count': 2, 'random_split_count': 4, 'random_cnt_min': 30, 'random_cnt_max': 160, 'random_max_epochs': 15, 'logged_metrics': {'loss': tensor(177.4364), 'seq_len': tensor(93.2904)}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type            | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | _loss              | ContrastiveLoss | 0      | train\n",
            "1 | _seq_encoder       | RnnSeqEncoder   | 297 K  | train\n",
            "2 | _validation_metric | BatchRecallTopK | 0      | train\n",
            "3 | _head              | Head            | 0      | train\n",
            "---------------------------------------------------------------\n",
            "297 K     Trainable params\n",
            "0         Non-trainable params\n",
            "297 K     Total params\n",
            "1.189     Total estimated model params size (MB)\n",
            "16        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=9` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': tensor(187.2166), 'seq_len': tensor(64.8889)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num': ['amount_rur'], 'cat': None, 'random_noise': 0.012135348146689685, 'random_linear_projection': 32, 'random_type': 'lstm', 'random_lr': 0.01, 'random_margin': 0.30000000000000004, 'random_neg_count': 1, 'random_split_count': 3, 'random_cnt_min': 25, 'random_cnt_max': 105, 'random_max_epochs': 9, 'logged_metrics': {'loss': tensor(187.2166), 'seq_len': tensor(64.8889)}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ошибка на итерации 70: cuDNN error: CUDNN_STATUS_BAD_PARAM\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type            | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | _loss              | ContrastiveLoss | 0      | train\n",
            "1 | _seq_encoder       | RnnSeqEncoder   | 527 K  | train\n",
            "2 | _validation_metric | BatchRecallTopK | 0      | train\n",
            "3 | _head              | Head            | 0      | train\n",
            "---------------------------------------------------------------\n",
            "527 K     Trainable params\n",
            "0         Non-trainable params\n",
            "527 K     Total params\n",
            "2.108     Total estimated model params size (MB)\n",
            "16        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=13` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': tensor(182.9944), 'seq_len': tensor(125.9253)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num': ['amount_rur'], 'cat': None, 'random_noise': 0.09623255437485428, 'random_linear_projection': 256, 'random_type': 'lstm', 'random_lr': 0.005, 'random_margin': 0.1, 'random_neg_count': 3, 'random_split_count': 3, 'random_cnt_min': 40, 'random_cnt_max': 215, 'random_max_epochs': 13, 'logged_metrics': {'loss': tensor(182.9944), 'seq_len': tensor(125.9253)}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type            | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | _loss              | ContrastiveLoss | 0      | train\n",
            "1 | _seq_encoder       | RnnSeqEncoder   | 321 K  | train\n",
            "2 | _validation_metric | BatchRecallTopK | 0      | train\n",
            "3 | _head              | Head            | 0      | train\n",
            "---------------------------------------------------------------\n",
            "321 K     Trainable params\n",
            "0         Non-trainable params\n",
            "321 K     Total params\n",
            "1.287     Total estimated model params size (MB)\n",
            "18        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=12` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': tensor(300.4221), 'seq_len': tensor(134.1432)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num': ['amount_rur'], 'cat': ['trans_date'], 'emb_dim_trans_date': 32, 'random_noise': 0.05535318590030465, 'random_linear_projection': 32, 'random_type': 'lstm', 'random_lr': 0.0003, 'random_margin': 0.8, 'random_neg_count': 2, 'random_split_count': 4, 'random_cnt_min': 35, 'random_cnt_max': 235, 'random_max_epochs': 12, 'logged_metrics': {'loss': tensor(300.4221), 'seq_len': tensor(134.1432)}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type            | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | _loss              | ContrastiveLoss | 0      | train\n",
            "1 | _seq_encoder       | RnnSeqEncoder   | 434 K  | train\n",
            "2 | _validation_metric | BatchRecallTopK | 0      | train\n",
            "3 | _head              | Head            | 0      | train\n",
            "---------------------------------------------------------------\n",
            "434 K     Trainable params\n",
            "0         Non-trainable params\n",
            "434 K     Total params\n",
            "1.738     Total estimated model params size (MB)\n",
            "20        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=11` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': tensor(167.5804), 'seq_len': tensor(132.9583)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num': ['amount_rur'], 'cat': ['trans_date', 'small_group'], 'emb_dim_trans_date': 32, 'emb_dim_small_group': 16, 'random_noise': 0.07037715011182598, 'random_linear_projection': 256, 'random_type': 'gru', 'random_lr': 0.01, 'random_margin': 0.2, 'random_neg_count': 3, 'random_split_count': 4, 'random_cnt_min': 30, 'random_cnt_max': 240, 'random_max_epochs': 11, 'logged_metrics': {'loss': tensor(167.5804), 'seq_len': tensor(132.9583)}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type            | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | _loss              | ContrastiveLoss | 0      | train\n",
            "1 | _seq_encoder       | RnnSeqEncoder   | 398 K  | train\n",
            "2 | _validation_metric | BatchRecallTopK | 0      | train\n",
            "3 | _head              | Head            | 0      | train\n",
            "---------------------------------------------------------------\n",
            "398 K     Trainable params\n",
            "0         Non-trainable params\n",
            "398 K     Total params\n",
            "1.593     Total estimated model params size (MB)\n",
            "15        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=11` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': tensor(114.5368), 'seq_len': tensor(68.5191)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num': None, 'cat': ['small_group'], 'emb_dim_small_group': 8, 'random_noise': 0.09572980411436899, 'random_linear_projection': 128, 'random_type': 'lstm', 'random_lr': 0.005, 'random_margin': 0.9, 'random_neg_count': 2, 'random_split_count': 3, 'random_cnt_min': 30, 'random_cnt_max': 110, 'random_max_epochs': 11, 'logged_metrics': {'loss': tensor(114.5368), 'seq_len': tensor(68.5191)}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type            | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | _loss              | ContrastiveLoss | 0      | train\n",
            "1 | _seq_encoder       | RnnSeqEncoder   | 395 K  | train\n",
            "2 | _validation_metric | BatchRecallTopK | 0      | train\n",
            "3 | _head              | Head            | 0      | train\n",
            "---------------------------------------------------------------\n",
            "395 K     Trainable params\n",
            "0         Non-trainable params\n",
            "395 K     Total params\n",
            "1.582     Total estimated model params size (MB)\n",
            "16        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=7` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': tensor(93.3097), 'seq_len': tensor(72.5208)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num': ['amount_rur'], 'cat': None, 'random_noise': 0.07420840994728722, 'random_linear_projection': 256, 'random_type': 'gru', 'random_lr': 0.0001, 'random_margin': 0.8, 'random_neg_count': 2, 'random_split_count': 2, 'random_cnt_min': 35, 'random_cnt_max': 110, 'random_max_epochs': 7, 'logged_metrics': {'loss': tensor(93.3097), 'seq_len': tensor(72.5208)}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type            | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | _loss              | ContrastiveLoss | 0      | train\n",
            "1 | _seq_encoder       | RnnSeqEncoder   | 325 K  | train\n",
            "2 | _validation_metric | BatchRecallTopK | 0      | train\n",
            "3 | _head              | Head            | 0      | train\n",
            "---------------------------------------------------------------\n",
            "325 K     Trainable params\n",
            "0         Non-trainable params\n",
            "325 K     Total params\n",
            "1.302     Total estimated model params size (MB)\n",
            "17        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=12` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': tensor(41.6362), 'seq_len': tensor(64.1536)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num': None, 'cat': ['small_group', 'trans_date'], 'emb_dim_small_group': 4, 'emb_dim_trans_date': 32, 'random_noise': 0.03081579038271617, 'random_linear_projection': 128, 'random_type': 'gru', 'random_lr': 0.005, 'random_margin': 1.0, 'random_neg_count': 1, 'random_split_count': 2, 'random_cnt_min': 35, 'random_cnt_max': 90, 'random_max_epochs': 12, 'logged_metrics': {'loss': tensor(41.6362), 'seq_len': tensor(64.1536)}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ошибка на итерации 76: cuDNN error: CUDNN_STATUS_BAD_PARAM\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type            | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | _loss              | ContrastiveLoss | 0      | train\n",
            "1 | _seq_encoder       | RnnSeqEncoder   | 565 K  | train\n",
            "2 | _validation_metric | BatchRecallTopK | 0      | train\n",
            "3 | _head              | Head            | 0      | train\n",
            "---------------------------------------------------------------\n",
            "565 K     Trainable params\n",
            "0         Non-trainable params\n",
            "565 K     Total params\n",
            "2.263     Total estimated model params size (MB)\n",
            "17        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=15` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': tensor(102.5175), 'seq_len': tensor(86.8125)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num': None, 'cat': ['trans_date', 'small_group'], 'emb_dim_trans_date': 32, 'emb_dim_small_group': 16, 'random_noise': 0.04591099188989315, 'random_linear_projection': 256, 'random_type': 'lstm', 'random_lr': 0.005, 'random_margin': 0.6, 'random_neg_count': 3, 'random_split_count': 3, 'random_cnt_min': 45, 'random_cnt_max': 130, 'random_max_epochs': 15, 'logged_metrics': {'loss': tensor(102.5175), 'seq_len': tensor(86.8125)}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type            | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | _loss              | ContrastiveLoss | 0      | train\n",
            "1 | _seq_encoder       | RnnSeqEncoder   | 410 K  | train\n",
            "2 | _validation_metric | BatchRecallTopK | 0      | train\n",
            "3 | _head              | Head            | 0      | train\n",
            "---------------------------------------------------------------\n",
            "410 K     Trainable params\n",
            "0         Non-trainable params\n",
            "410 K     Total params\n",
            "1.643     Total estimated model params size (MB)\n",
            "17        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=9` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': tensor(51.7602), 'seq_len': tensor(134.8229)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num': None, 'cat': ['trans_date', 'small_group'], 'emb_dim_trans_date': 16, 'emb_dim_small_group': 4, 'random_noise': 0.015579986783132806, 'random_linear_projection': 128, 'random_type': 'lstm', 'random_lr': 0.0003, 'random_margin': 0.9, 'random_neg_count': 1, 'random_split_count': 2, 'random_cnt_min': 30, 'random_cnt_max': 240, 'random_max_epochs': 9, 'logged_metrics': {'loss': tensor(51.7602), 'seq_len': tensor(134.8229)}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ошибка на итерации 78: cuDNN error: CUDNN_STATUS_BAD_PARAM\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type            | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | _loss              | ContrastiveLoss | 0      | train\n",
            "1 | _seq_encoder       | RnnSeqEncoder   | 395 K  | train\n",
            "2 | _validation_metric | BatchRecallTopK | 0      | train\n",
            "3 | _head              | Head            | 0      | train\n",
            "---------------------------------------------------------------\n",
            "395 K     Trainable params\n",
            "0         Non-trainable params\n",
            "395 K     Total params\n",
            "1.582     Total estimated model params size (MB)\n",
            "16        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=9` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': tensor(300.4779), 'seq_len': tensor(83.5859)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num': ['amount_rur'], 'cat': None, 'random_noise': 0.06447475475730258, 'random_linear_projection': 256, 'random_type': 'gru', 'random_lr': 0.001, 'random_margin': 1.0, 'random_neg_count': 3, 'random_split_count': 4, 'random_cnt_min': 45, 'random_cnt_max': 120, 'random_max_epochs': 9, 'logged_metrics': {'loss': tensor(300.4779), 'seq_len': tensor(83.5859)}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type            | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | _loss              | ContrastiveLoss | 0      | train\n",
            "1 | _seq_encoder       | RnnSeqEncoder   | 232 K  | train\n",
            "2 | _validation_metric | BatchRecallTopK | 0      | train\n",
            "3 | _head              | Head            | 0      | train\n",
            "---------------------------------------------------------------\n",
            "232 K     Trainable params\n",
            "0         Non-trainable params\n",
            "232 K     Total params\n",
            "0.931     Total estimated model params size (MB)\n",
            "17        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=11` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': tensor(116.4732), 'seq_len': tensor(52.5972)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num': None, 'cat': ['trans_date', 'small_group'], 'emb_dim_trans_date': 8, 'emb_dim_small_group': 16, 'random_noise': 0.051624436257450924, 'random_linear_projection': 32, 'random_type': 'gru', 'random_lr': 0.005, 'random_margin': 0.4, 'random_neg_count': 3, 'random_split_count': 3, 'random_cnt_min': 30, 'random_cnt_max': 75, 'random_max_epochs': 11, 'logged_metrics': {'loss': tensor(116.4732), 'seq_len': tensor(52.5972)}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type            | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | _loss              | ContrastiveLoss | 0      | train\n",
            "1 | _seq_encoder       | RnnSeqEncoder   | 527 K  | train\n",
            "2 | _validation_metric | BatchRecallTopK | 0      | train\n",
            "3 | _head              | Head            | 0      | train\n",
            "---------------------------------------------------------------\n",
            "527 K     Trainable params\n",
            "0         Non-trainable params\n",
            "527 K     Total params\n",
            "2.108     Total estimated model params size (MB)\n",
            "16        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=8` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': tensor(254.4243), 'seq_len': tensor(96.2587)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num': ['amount_rur'], 'cat': None, 'random_noise': 0.05264528146075828, 'random_linear_projection': 256, 'random_type': 'lstm', 'random_lr': 0.0003, 'random_margin': 0.30000000000000004, 'random_neg_count': 2, 'random_split_count': 3, 'random_cnt_min': 45, 'random_cnt_max': 145, 'random_max_epochs': 8, 'logged_metrics': {'loss': tensor(254.4243), 'seq_len': tensor(96.2587)}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type            | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | _loss              | ContrastiveLoss | 0      | train\n",
            "1 | _seq_encoder       | RnnSeqEncoder   | 297 K  | train\n",
            "2 | _validation_metric | BatchRecallTopK | 0      | train\n",
            "3 | _head              | Head            | 0      | train\n",
            "---------------------------------------------------------------\n",
            "297 K     Trainable params\n",
            "0         Non-trainable params\n",
            "297 K     Total params\n",
            "1.189     Total estimated model params size (MB)\n",
            "16        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=5` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': tensor(26.2457), 'seq_len': tensor(111.3750)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num': ['amount_rur'], 'cat': None, 'random_noise': 0.062402746712751325, 'random_linear_projection': 32, 'random_type': 'lstm', 'random_lr': 0.001, 'random_margin': 0.5, 'random_neg_count': 2, 'random_split_count': 1, 'random_cnt_min': 30, 'random_cnt_max': 200, 'random_max_epochs': 5, 'logged_metrics': {'loss': tensor(26.2457), 'seq_len': tensor(111.3750)}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type            | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | _loss              | ContrastiveLoss | 0      | train\n",
            "1 | _seq_encoder       | RnnSeqEncoder   | 330 K  | train\n",
            "2 | _validation_metric | BatchRecallTopK | 0      | train\n",
            "3 | _head              | Head            | 0      | train\n",
            "---------------------------------------------------------------\n",
            "330 K     Trainable params\n",
            "0         Non-trainable params\n",
            "330 K     Total params\n",
            "1.320     Total estimated model params size (MB)\n",
            "16        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=10` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': tensor(5.1953), 'seq_len': tensor(104.2865)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num': ['amount_rur'], 'cat': None, 'random_noise': 0.02837383189844549, 'random_linear_projection': 64, 'random_type': 'lstm', 'random_lr': 0.001, 'random_margin': 0.8, 'random_neg_count': 1, 'random_split_count': 1, 'random_cnt_min': 10, 'random_cnt_max': 190, 'random_max_epochs': 10, 'logged_metrics': {'loss': tensor(5.1953), 'seq_len': tensor(104.2865)}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type            | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | _loss              | ContrastiveLoss | 0      | train\n",
            "1 | _seq_encoder       | RnnSeqEncoder   | 403 K  | train\n",
            "2 | _validation_metric | BatchRecallTopK | 0      | train\n",
            "3 | _head              | Head            | 0      | train\n",
            "---------------------------------------------------------------\n",
            "403 K     Trainable params\n",
            "0         Non-trainable params\n",
            "403 K     Total params\n",
            "1.614     Total estimated model params size (MB)\n",
            "18        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=14` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': tensor(248.1212), 'seq_len': tensor(122.1732)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num': ['amount_rur'], 'cat': ['trans_date'], 'emb_dim_trans_date': 8, 'random_noise': 0.015266331394925836, 'random_linear_projection': 256, 'random_type': 'gru', 'random_lr': 0.005, 'random_margin': 0.30000000000000004, 'random_neg_count': 3, 'random_split_count': 4, 'random_cnt_min': 25, 'random_cnt_max': 225, 'random_max_epochs': 14, 'logged_metrics': {'loss': tensor(248.1212), 'seq_len': tensor(122.1732)}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type            | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | _loss              | ContrastiveLoss | 0      | train\n",
            "1 | _seq_encoder       | RnnSeqEncoder   | 395 K  | train\n",
            "2 | _validation_metric | BatchRecallTopK | 0      | train\n",
            "3 | _head              | Head            | 0      | train\n",
            "---------------------------------------------------------------\n",
            "395 K     Trainable params\n",
            "0         Non-trainable params\n",
            "395 K     Total params\n",
            "1.583     Total estimated model params size (MB)\n",
            "16        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=13` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': tensor(75.1530), 'seq_len': tensor(107.7214)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num': ['amount_rur'], 'cat': None, 'random_noise': 0.05182976443716028, 'random_linear_projection': 128, 'random_type': 'lstm', 'random_lr': 0.005, 'random_margin': 0.4, 'random_neg_count': 2, 'random_split_count': 2, 'random_cnt_min': 45, 'random_cnt_max': 170, 'random_max_epochs': 13, 'logged_metrics': {'loss': tensor(75.1530), 'seq_len': tensor(107.7214)}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type            | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | _loss              | ContrastiveLoss | 0      | train\n",
            "1 | _seq_encoder       | RnnSeqEncoder   | 296 K  | train\n",
            "2 | _validation_metric | BatchRecallTopK | 0      | train\n",
            "3 | _head              | Head            | 0      | train\n",
            "---------------------------------------------------------------\n",
            "296 K     Trainable params\n",
            "0         Non-trainable params\n",
            "296 K     Total params\n",
            "1.188     Total estimated model params size (MB)\n",
            "16        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=11` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': tensor(0.0527), 'seq_len': tensor(69.5938)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num': ['amount_rur'], 'cat': None, 'random_noise': 0.09613883781186262, 'random_linear_projection': 128, 'random_type': 'gru', 'random_lr': 0.0003, 'random_margin': 0.2, 'random_neg_count': 1, 'random_split_count': 1, 'random_cnt_min': 35, 'random_cnt_max': 105, 'random_max_epochs': 11, 'logged_metrics': {'loss': tensor(0.0527), 'seq_len': tensor(69.5938)}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type            | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | _loss              | ContrastiveLoss | 0      | train\n",
            "1 | _seq_encoder       | RnnSeqEncoder   | 538 K  | train\n",
            "2 | _validation_metric | BatchRecallTopK | 0      | train\n",
            "3 | _head              | Head            | 0      | train\n",
            "---------------------------------------------------------------\n",
            "538 K     Trainable params\n",
            "0         Non-trainable params\n",
            "538 K     Total params\n",
            "2.154     Total estimated model params size (MB)\n",
            "20        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=9` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': tensor(0.), 'seq_len': tensor(126.6667)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num': ['amount_rur'], 'cat': ['small_group', 'trans_date'], 'emb_dim_small_group': 16, 'emb_dim_trans_date': 4, 'random_noise': 0.015905174226739427, 'random_linear_projection': 256, 'random_type': 'lstm', 'random_lr': 0.005, 'random_margin': 0.8, 'random_neg_count': 3, 'random_split_count': 1, 'random_cnt_min': 25, 'random_cnt_max': 220, 'random_max_epochs': 9, 'logged_metrics': {'loss': tensor(0.), 'seq_len': tensor(126.6667)}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ошибка на итерации 87: cuDNN error: CUDNN_STATUS_BAD_PARAM\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type            | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | _loss              | ContrastiveLoss | 0      | train\n",
            "1 | _seq_encoder       | RnnSeqEncoder   | 310 K  | train\n",
            "2 | _validation_metric | BatchRecallTopK | 0      | train\n",
            "3 | _head              | Head            | 0      | train\n",
            "---------------------------------------------------------------\n",
            "310 K     Trainable params\n",
            "0         Non-trainable params\n",
            "310 K     Total params\n",
            "1.242     Total estimated model params size (MB)\n",
            "17        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=14` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': tensor(59.5173), 'seq_len': tensor(108.1849)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num': None, 'cat': ['trans_date', 'small_group'], 'emb_dim_trans_date': 16, 'emb_dim_small_group': 4, 'random_noise': 0.09087860298797269, 'random_linear_projection': 32, 'random_type': 'lstm', 'random_lr': 0.0003, 'random_margin': 0.5, 'random_neg_count': 3, 'random_split_count': 2, 'random_cnt_min': 10, 'random_cnt_max': 205, 'random_max_epochs': 14, 'logged_metrics': {'loss': tensor(59.5173), 'seq_len': tensor(108.1849)}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type            | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | _loss              | ContrastiveLoss | 0      | train\n",
            "1 | _seq_encoder       | RnnSeqEncoder   | 434 K  | train\n",
            "2 | _validation_metric | BatchRecallTopK | 0      | train\n",
            "3 | _head              | Head            | 0      | train\n",
            "---------------------------------------------------------------\n",
            "434 K     Trainable params\n",
            "0         Non-trainable params\n",
            "434 K     Total params\n",
            "1.737     Total estimated model params size (MB)\n",
            "17        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=17` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': tensor(98.8011), 'seq_len': tensor(109.3438)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num': None, 'cat': ['trans_date', 'small_group'], 'emb_dim_trans_date': 32, 'emb_dim_small_group': 16, 'random_noise': 0.019653216706610813, 'random_linear_projection': 256, 'random_type': 'gru', 'random_lr': 0.001, 'random_margin': 0.7000000000000001, 'random_neg_count': 1, 'random_split_count': 3, 'random_cnt_min': 25, 'random_cnt_max': 200, 'random_max_epochs': 17, 'logged_metrics': {'loss': tensor(98.8011), 'seq_len': tensor(109.3438)}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type            | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | _loss              | ContrastiveLoss | 0      | train\n",
            "1 | _seq_encoder       | RnnSeqEncoder   | 249 K  | train\n",
            "2 | _validation_metric | BatchRecallTopK | 0      | train\n",
            "3 | _head              | Head            | 0      | train\n",
            "---------------------------------------------------------------\n",
            "249 K     Trainable params\n",
            "0         Non-trainable params\n",
            "249 K     Total params\n",
            "0.997     Total estimated model params size (MB)\n",
            "20        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=14` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': tensor(0.), 'seq_len': tensor(103.7344)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num': ['amount_rur'], 'cat': ['small_group', 'trans_date'], 'emb_dim_small_group': 8, 'emb_dim_trans_date': 32, 'random_noise': 0.029718447271916526, 'random_linear_projection': 32, 'random_type': 'gru', 'random_lr': 0.0003, 'random_margin': 0.6, 'random_neg_count': 3, 'random_split_count': 1, 'random_cnt_min': 15, 'random_cnt_max': 210, 'random_max_epochs': 14, 'logged_metrics': {'loss': tensor(0.), 'seq_len': tensor(103.7344)}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type            | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | _loss              | ContrastiveLoss | 0      | train\n",
            "1 | _seq_encoder       | RnnSeqEncoder   | 298 K  | train\n",
            "2 | _validation_metric | BatchRecallTopK | 0      | train\n",
            "3 | _head              | Head            | 0      | train\n",
            "---------------------------------------------------------------\n",
            "298 K     Trainable params\n",
            "0         Non-trainable params\n",
            "298 K     Total params\n",
            "1.193     Total estimated model params size (MB)\n",
            "15        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=7` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': tensor(144.3392), 'seq_len': tensor(52.7760)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num': None, 'cat': ['small_group'], 'emb_dim_small_group': 4, 'random_noise': 0.08511854920203103, 'random_linear_projection': 128, 'random_type': 'gru', 'random_lr': 0.0003, 'random_margin': 0.4, 'random_neg_count': 3, 'random_split_count': 3, 'random_cnt_min': 20, 'random_cnt_max': 85, 'random_max_epochs': 7, 'logged_metrics': {'loss': tensor(144.3392), 'seq_len': tensor(52.7760)}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ошибка на итерации 91: cuDNN error: CUDNN_STATUS_BAD_PARAM\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ошибка на итерации 91: cuDNN error: CUDNN_STATUS_BAD_PARAM\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type            | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | _loss              | ContrastiveLoss | 0      | train\n",
            "1 | _seq_encoder       | RnnSeqEncoder   | 299 K  | train\n",
            "2 | _validation_metric | BatchRecallTopK | 0      | train\n",
            "3 | _head              | Head            | 0      | train\n",
            "---------------------------------------------------------------\n",
            "299 K     Trainable params\n",
            "0         Non-trainable params\n",
            "299 K     Total params\n",
            "1.198     Total estimated model params size (MB)\n",
            "15        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=7` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': tensor(141.1620), 'seq_len': tensor(52.8038)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num': None, 'cat': ['small_group'], 'emb_dim_small_group': 8, 'random_noise': 0.012592281897942426, 'random_linear_projection': 128, 'random_type': 'gru', 'random_lr': 0.0003, 'random_margin': 0.30000000000000004, 'random_neg_count': 1, 'random_split_count': 3, 'random_cnt_min': 10, 'random_cnt_max': 100, 'random_max_epochs': 7, 'logged_metrics': {'loss': tensor(141.1620), 'seq_len': tensor(52.8038)}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type            | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | _loss              | ContrastiveLoss | 0      | train\n",
            "1 | _seq_encoder       | RnnSeqEncoder   | 541 K  | train\n",
            "2 | _validation_metric | BatchRecallTopK | 0      | train\n",
            "3 | _head              | Head            | 0      | train\n",
            "---------------------------------------------------------------\n",
            "541 K     Trainable params\n",
            "0         Non-trainable params\n",
            "541 K     Total params\n",
            "2.166     Total estimated model params size (MB)\n",
            "15        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=7` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': tensor(233.8121), 'seq_len': tensor(47.2826)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num': None, 'cat': ['small_group'], 'emb_dim_small_group': 32, 'random_noise': 0.04283500267732983, 'random_linear_projection': 256, 'random_type': 'lstm', 'random_lr': 0.001, 'random_margin': 0.7000000000000001, 'random_neg_count': 1, 'random_split_count': 4, 'random_cnt_min': 30, 'random_cnt_max': 65, 'random_max_epochs': 7, 'logged_metrics': {'loss': tensor(233.8121), 'seq_len': tensor(47.2826)}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ошибка на итерации 93: cuDNN error: CUDNN_STATUS_BAD_PARAM\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type            | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | _loss              | ContrastiveLoss | 0      | train\n",
            "1 | _seq_encoder       | RnnSeqEncoder   | 325 K  | train\n",
            "2 | _validation_metric | BatchRecallTopK | 0      | train\n",
            "3 | _head              | Head            | 0      | train\n",
            "---------------------------------------------------------------\n",
            "325 K     Trainable params\n",
            "0         Non-trainable params\n",
            "325 K     Total params\n",
            "1.302     Total estimated model params size (MB)\n",
            "20        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=13` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': tensor(38.0383), 'seq_len': tensor(99.1042)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num': ['amount_rur'], 'cat': ['trans_date', 'small_group'], 'emb_dim_trans_date': 32, 'emb_dim_small_group': 16, 'random_noise': 0.0879328302828129, 'random_linear_projection': 32, 'random_type': 'lstm', 'random_lr': 0.01, 'random_margin': 0.7000000000000001, 'random_neg_count': 2, 'random_split_count': 2, 'random_cnt_min': 15, 'random_cnt_max': 180, 'random_max_epochs': 13, 'logged_metrics': {'loss': tensor(38.0383), 'seq_len': tensor(99.1042)}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ошибка на итерации 94: cuDNN error: CUDNN_STATUS_BAD_PARAM\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type            | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | _loss              | ContrastiveLoss | 0      | train\n",
            "1 | _seq_encoder       | RnnSeqEncoder   | 401 K  | train\n",
            "2 | _validation_metric | BatchRecallTopK | 0      | train\n",
            "3 | _head              | Head            | 0      | train\n",
            "---------------------------------------------------------------\n",
            "401 K     Trainable params\n",
            "0         Non-trainable params\n",
            "401 K     Total params\n",
            "1.607     Total estimated model params size (MB)\n",
            "20        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=6` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': tensor(96.3803), 'seq_len': tensor(105.1493)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num': ['amount_rur'], 'cat': ['trans_date', 'small_group'], 'emb_dim_trans_date': 4, 'emb_dim_small_group': 8, 'random_noise': 0.07641736437048474, 'random_linear_projection': 128, 'random_type': 'lstm', 'random_lr': 0.01, 'random_margin': 0.9, 'random_neg_count': 3, 'random_split_count': 3, 'random_cnt_min': 45, 'random_cnt_max': 170, 'random_max_epochs': 6, 'logged_metrics': {'loss': tensor(96.3803), 'seq_len': tensor(105.1493)}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type            | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | _loss              | ContrastiveLoss | 0      | train\n",
            "1 | _seq_encoder       | RnnSeqEncoder   | 397 K  | train\n",
            "2 | _validation_metric | BatchRecallTopK | 0      | train\n",
            "3 | _head              | Head            | 0      | train\n",
            "---------------------------------------------------------------\n",
            "397 K     Trainable params\n",
            "0         Non-trainable params\n",
            "397 K     Total params\n",
            "1.588     Total estimated model params size (MB)\n",
            "18        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=6` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': tensor(61.5729), 'seq_len': tensor(60.5964)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num': ['amount_rur'], 'cat': ['small_group'], 'emb_dim_small_group': 4, 'random_noise': 0.020568057575061673, 'random_linear_projection': 128, 'random_type': 'lstm', 'random_lr': 0.0001, 'random_margin': 0.2, 'random_neg_count': 3, 'random_split_count': 2, 'random_cnt_min': 45, 'random_cnt_max': 75, 'random_max_epochs': 6, 'logged_metrics': {'loss': tensor(61.5729), 'seq_len': tensor(60.5964)}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ошибка на итерации 96: cuDNN error: CUDNN_STATUS_BAD_PARAM\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ошибка на итерации 96: cuDNN error: CUDNN_STATUS_BAD_PARAM\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type            | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | _loss              | ContrastiveLoss | 0      | train\n",
            "1 | _seq_encoder       | RnnSeqEncoder   | 296 K  | train\n",
            "2 | _validation_metric | BatchRecallTopK | 0      | train\n",
            "3 | _head              | Head            | 0      | train\n",
            "---------------------------------------------------------------\n",
            "296 K     Trainable params\n",
            "0         Non-trainable params\n",
            "296 K     Total params\n",
            "1.188     Total estimated model params size (MB)\n",
            "16        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=8` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': tensor(267.9740), 'seq_len': tensor(69.0260)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num': ['amount_rur'], 'cat': None, 'random_noise': 0.09361964643720427, 'random_linear_projection': 128, 'random_type': 'gru', 'random_lr': 0.0001, 'random_margin': 0.1, 'random_neg_count': 2, 'random_split_count': 3, 'random_cnt_min': 45, 'random_cnt_max': 95, 'random_max_epochs': 8, 'logged_metrics': {'loss': tensor(267.9740), 'seq_len': tensor(69.0260)}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type            | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | _loss              | ContrastiveLoss | 0      | train\n",
            "1 | _seq_encoder       | RnnSeqEncoder   | 411 K  | train\n",
            "2 | _validation_metric | BatchRecallTopK | 0      | train\n",
            "3 | _head              | Head            | 0      | train\n",
            "---------------------------------------------------------------\n",
            "411 K     Trainable params\n",
            "0         Non-trainable params\n",
            "411 K     Total params\n",
            "1.644     Total estimated model params size (MB)\n",
            "15        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=11` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': tensor(0.), 'seq_len': tensor(143.8542)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num': None, 'cat': ['trans_date'], 'emb_dim_trans_date': 16, 'random_noise': 0.029922574605336982, 'random_linear_projection': 256, 'random_type': 'gru', 'random_lr': 0.0003, 'random_margin': 0.30000000000000004, 'random_neg_count': 1, 'random_split_count': 1, 'random_cnt_min': 45, 'random_cnt_max': 245, 'random_max_epochs': 11, 'logged_metrics': {'loss': tensor(0.), 'seq_len': tensor(143.8542)}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type            | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | _loss              | ContrastiveLoss | 0      | train\n",
            "1 | _seq_encoder       | RnnSeqEncoder   | 331 K  | train\n",
            "2 | _validation_metric | BatchRecallTopK | 0      | train\n",
            "3 | _head              | Head            | 0      | train\n",
            "---------------------------------------------------------------\n",
            "331 K     Trainable params\n",
            "0         Non-trainable params\n",
            "331 K     Total params\n",
            "1.324     Total estimated model params size (MB)\n",
            "15        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=16` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': tensor(140.0127), 'seq_len': tensor(98.2483)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num': None, 'cat': ['small_group'], 'emb_dim_small_group': 4, 'random_noise': 0.09216975571103518, 'random_linear_projection': 64, 'random_type': 'lstm', 'random_lr': 0.0003, 'random_margin': 0.6, 'random_neg_count': 2, 'random_split_count': 3, 'random_cnt_min': 20, 'random_cnt_max': 170, 'random_max_epochs': 16, 'logged_metrics': {'loss': tensor(140.0127), 'seq_len': tensor(98.2483)}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ошибка на итерации 99: cuDNN error: CUDNN_STATUS_BAD_PARAM\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type            | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | _loss              | ContrastiveLoss | 0      | train\n",
            "1 | _seq_encoder       | RnnSeqEncoder   | 324 K  | train\n",
            "2 | _validation_metric | BatchRecallTopK | 0      | train\n",
            "3 | _head              | Head            | 0      | train\n",
            "---------------------------------------------------------------\n",
            "324 K     Trainable params\n",
            "0         Non-trainable params\n",
            "324 K     Total params\n",
            "1.298     Total estimated model params size (MB)\n",
            "18        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=5` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': tensor(268.2064), 'seq_len': tensor(47.9688)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num': ['amount_rur'], 'cat': ['trans_date'], 'emb_dim_trans_date': 32, 'random_noise': 0.06295681687099948, 'random_linear_projection': 128, 'random_type': 'gru', 'random_lr': 0.005, 'random_margin': 0.5, 'random_neg_count': 3, 'random_split_count': 4, 'random_cnt_min': 15, 'random_cnt_max': 80, 'random_max_epochs': 5, 'logged_metrics': {'loss': tensor(268.2064), 'seq_len': tensor(47.9688)}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type            | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | _loss              | ContrastiveLoss | 0      | train\n",
            "1 | _seq_encoder       | RnnSeqEncoder   | 434 K  | train\n",
            "2 | _validation_metric | BatchRecallTopK | 0      | train\n",
            "3 | _head              | Head            | 0      | train\n",
            "---------------------------------------------------------------\n",
            "434 K     Trainable params\n",
            "0         Non-trainable params\n",
            "434 K     Total params\n",
            "1.737     Total estimated model params size (MB)\n",
            "17        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=13` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': tensor(0.), 'seq_len': tensor(46.5938)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num': None, 'cat': ['trans_date', 'small_group'], 'emb_dim_trans_date': 32, 'emb_dim_small_group': 16, 'random_noise': 0.07661867016717669, 'random_linear_projection': 256, 'random_type': 'gru', 'random_lr': 0.001, 'random_margin': 0.2, 'random_neg_count': 1, 'random_split_count': 1, 'random_cnt_min': 15, 'random_cnt_max': 75, 'random_max_epochs': 13, 'logged_metrics': {'loss': tensor(0.), 'seq_len': tensor(46.5938)}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type            | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | _loss              | ContrastiveLoss | 0      | train\n",
            "1 | _seq_encoder       | RnnSeqEncoder   | 303 K  | train\n",
            "2 | _validation_metric | BatchRecallTopK | 0      | train\n",
            "3 | _head              | Head            | 0      | train\n",
            "---------------------------------------------------------------\n",
            "303 K     Trainable params\n",
            "0         Non-trainable params\n",
            "303 K     Total params\n",
            "1.214     Total estimated model params size (MB)\n",
            "18        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=9` reached.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': tensor(274.2792), 'seq_len': tensor(20.0430)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num': ['amount_rur'], 'cat': ['trans_date'], 'emb_dim_trans_date': 8, 'random_noise': 0.026166513280216852, 'random_linear_projection': 32, 'random_type': 'lstm', 'random_lr': 0.01, 'random_margin': 0.30000000000000004, 'random_neg_count': 1, 'random_split_count': 4, 'random_cnt_min': 15, 'random_cnt_max': 25, 'random_max_epochs': 9, 'logged_metrics': {'loss': tensor(274.2792), 'seq_len': tensor(20.0430)}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ],
      "metadata": {
        "id": "O_k_gh9VJ8q7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gP78of3tZz0G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}