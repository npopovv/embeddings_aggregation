{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FyoPY1A28SIh"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import sys\n",
    "!pip install mteb\n",
    "!pip install -q transformers accelerate bitsandbytes\n",
    "! pip install git+https://github.com/simonzhang00/ripser-plusplus.git\n",
    "! pip install git+https://github.com/IlyaTrofimov/RTD.git\n",
    "!git clone https://github.com/mklabunde/resi.git\n",
    "# !cd resi && pip install -r requirements.txt && pip install -e .\n",
    "!pip install loguru\n",
    "!pip install git+https://github.com/KhrulkovV/geometry-score.git\n",
    "!pip install git+https://github.com/xgfs/imd.git\n",
    "!pip install gudhi\n",
    "!pip install hf_xet\n",
    "sys.path.append('/content/resi/')\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RFn6B7RmlexD"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from datasets import load_dataset\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import gc\n",
    "import os\n",
    "import cvxpy as cp\n",
    "\n",
    "\n",
    "from typing import List\n",
    "import mteb\n",
    "\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "\n",
    "\n",
    "from sklearn.decomposition import IncrementalPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F2fdL7YGZtxM",
    "outputId": "2dd5e786-6ed6-4c2c-f463-0cf52757e931"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-23 18:18:55.794\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrepsim.measures.rtd\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m56\u001b[0m - \u001b[1mRTD will use cuda devices to compute barcodes. It is not possible to specify which GPU directly. Use the CUDA_VISIBLE_DEVICES environment variable to specify which GPU to use.\u001b[0m\n",
      "\u001b[32m2025-05-23 18:18:55.795\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrepsim.measures.rtd\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m56\u001b[0m - \u001b[1mRTD will use cuda devices to compute barcodes. It is not possible to specify which GPU directly. Use the CUDA_VISIBLE_DEVICES environment variable to specify which GPU to use.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from repsim.measures import ALL_MEASURES\n",
    "from repsim.measures import FUNCTIONAL_SIMILARITY_MEASURES\n",
    "\n",
    "import pickle\n",
    "def save_res(dct, path):\n",
    "  with open(path, 'wb') as handle:\n",
    "      pickle.dump(dct, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_res(path):\n",
    "  try:\n",
    "    with open(path, 'rb') as handle:\n",
    "      results = pickle.load(handle)\n",
    "  except:\n",
    "    results = {}\n",
    "\n",
    "  return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-jKfTZKWYU5K",
    "outputId": "e9c54040-42d1-4c8e-8229-e5a773609369"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pPDELZtgg3Cl"
   },
   "source": [
    "# Считаем метрики похожести разных слоев модели CLS- токену + Pooler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5jAmNvCig8Pz"
   },
   "source": [
    "Тексты для расчета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 508,
     "referenced_widgets": [
      "ef58bd9c9a0642d6bc3e01b06a520579",
      "580991b8f34e41ca83c8c760b8fc5971",
      "f8a04dd181564f8cb1874afc365c20bf",
      "f49e197fb7f74655b728f50feb886742",
      "561a30839ec648dcbac345f50d847e97",
      "c87db6755b9841cf80e6b83777acc83d",
      "7f4978409e4c47d6b9e822682887f09a",
      "62fb8fbdc7ed429a863f11ca6c25b406",
      "291694589d8c43498fb2932acc4c870f",
      "4bcf8f3b913f49958bf0c060076ec945",
      "0eac58d8902249be8068dab9efa9f806",
      "4d0aae85ba714769bfd4ab6ea9a20ae0",
      "bfe3040ea4864ed0b1e82b01c3ad496f",
      "b85b98361c3c466f897df4458225f11d",
      "ef2d8d0aa8114de8894c6ea5f0789833",
      "199c7c68a3744b00a2bff09e5f21eb2e",
      "f2dd58452dbe4e05a547b787a07e6dcf",
      "cb3af3686a4e4ba1a245342f067209b6",
      "b948e699322743039294684924e346c5",
      "a96ef0491e0d4601baa069eef2115776",
      "4b158d77e8c942c8a10c8e53a53afc6d",
      "02e3b2def3af45a8901c5d5853b106a2",
      "dbac6dfffb804cf494f90d804ac0ea4a",
      "17b433a6ea9e46af9fece59f742c2504",
      "bdbccd84425c491cafd55a6857487a8a",
      "2228d264fc1f40ca9ec5aa6affe9135c",
      "0447143d68804729ab5bfc557de9a0a5",
      "488987f4eb804ac7a6b76b0250c96035",
      "7965cb3bcdb94059a8f18b55c0c09c11",
      "26e6d749eda44eae8539e672259f505a",
      "1e52ed6e47df4af4bbb4156411608502",
      "8236513341ee4d03b5c65eda5cf0ec51",
      "51c2f578e45f4ab5a3ee9fdb53ae2bd5",
      "22aa8fca9afa445f8dd5c48050a87aae",
      "96ed8be63b6b4c8391fd71ad83348bea",
      "6cf8526f401146328b849b5f45f9105f",
      "2c028db216a0436fb4c7a79a42bc4fbf",
      "108558ea70a64c84bfa888d2d0500e6c",
      "035f0eb9ff1a49fbbeef94508a4551bb",
      "e3ac6df1e8894572843e9e752fecf6d3",
      "9cabc4fc2ebf4552af0087e450700239",
      "e20d1a51ed8c4d8e9593fb4bce8d9600",
      "89cec0c032bd4206b680f401123bb0eb",
      "f91fa4c3536b4186a67dec1d25bab678",
      "437b972c286c4499898f4245e50a91b1",
      "e97a7c4527ec4f70845767bdf8e08a1a",
      "d449b56fd0144018999f1c3efffb9925",
      "81ed5374968647fe91804dd8f44f84a2",
      "6317477addb34fc2b3081a3624aaf92e",
      "74e17e8aa9ea45c0812b30b130be6f3d",
      "e51770a22957496c9e8089fe95526cae",
      "53945a64c1274e368fae3a2089b6185a",
      "7d49cc9874a0414e981228960d0475b7",
      "ddcdc305f9cc4ecabddb8c06ec16ea66",
      "fcc10d4e41bd4647a5ba71f7e31c6af6",
      "153253240d7c4f78aeb84cc7925213b5",
      "2e7e176ee8f44214a4a7ef1d890cca32",
      "3422f4cc4c4b4570a70c0b198324d1fa",
      "2ff21ab994ad4e49b96e957bae24bf22",
      "5c9410f1f0894660987d63fb1ff323f9",
      "087a9dec6a4947c8bcc779c8f04ebe6e",
      "4c19d5f0369f41169d6ed8a47e5e0141",
      "ae2b858e10ed40a68dc47e44279bc06e",
      "0046df47ba9648ce941a28823b6a1ea5",
      "88a7f4dfe6cd4ba1b6848dcca389469f",
      "88379484c77a4c59a69a5d770352b13a",
      "332c233ba44e494984f01a1c15dab976",
      "d6ee38b8b6344e71815ddd7e5c08851c",
      "e39f7fbea4d64a6ba575303a7d7504ed",
      "c905558be0a64c1184fb9e23b41386b0",
      "13d3918d813c41d58fd94b99a3a7bef0",
      "24429d9f80704b429da667019e7b5ed8",
      "6be5e49f626644aab148cf7387b0b8d8",
      "1206c54e4d0b4575897f89fc42b99999",
      "a4090f566a4b4ccd83d84a582b54c63f",
      "8d7766862527460eb9a883b9b6665f4d",
      "fd744b10d4b445f582f8b1523226c807",
      "641fa99692c64b49a3f78a8d02927abc",
      "94ea57d8780d40ecaf8b6277bd507ce0",
      "1ae0b56295384a21826b19ee17f2be9b",
      "c55d687adfa84319acdf83f0680232a7",
      "d52cf99014a341fa92de614c148e1b93",
      "b65dd0ecdd214a62af0b64fb2334b5e8",
      "95be0cb2118347b0aff105d2f912585f",
      "c12b65ffa57f4211bf6a8d595a4e702d",
      "6f2e591aa8eb404d922267cc463eaa6f",
      "94ebf5adc84640a79b569f63aa7b9c8d",
      "fcf3ab448e4d4f45ad91949d4f0b75a6",
      "a4df2aa0b3bc4149801fd8e1c17f9e4f",
      "c2c0166adc1a43d097547e0952666165",
      "e839e62389f9486a9c75562ced27c95e",
      "397ab8fd7470474b9094d4850703b184",
      "70fd17e7c19948cb9d219b2f139b85f2",
      "db24defcf5ac4dc1ba86a6c56811ce43",
      "9cfcd3768c834ab18aecfe4e414ea420",
      "f4aac65483e348958dfc563ef5d9e164",
      "c9ff0ca798934bca993f3dba3bb9281f",
      "34671417b17e4e59ad46c5399da7c602",
      "ff4d6c46e6ba4d22988612802e4ad39f",
      "03394a9b5a5c4c8fbd75d448d3474fcd",
      "9d917dd9e8744d188fc3560346a945fe",
      "a48492c2f9874d8183312968ee75f8f1",
      "43f1c2313b914b7dbeea7813a092d78e",
      "25cb7eaf746843a396f11f0be1d76298",
      "5c1e1e74e850423990cf4f377cb50f5d",
      "ee38d19b3ec0429cbe695e7967321b9f",
      "2bd6498998664174ac9b467d2ed2dd3b",
      "5469bf786d4f486a8c58e9362cf3f4b1",
      "52e39dd849014a32963044c313d69711",
      "1bbec0258c93467c91bda561b29f7970",
      "c64c51988ce34b2dbbc983171938e0ef",
      "839cd84e5de74f3d82e8ecbc2a6dfc30",
      "d620b0156685445c9cf39bae84fff200",
      "07e178b2309e4ac9ac2c561e70d43c06",
      "b952ac19af4f4c859b6fcfd4f952565b",
      "e011507276634e9a916000ce57453955",
      "b7bc77a2a2a04f5ea091e05e8203e185",
      "93891b4376e74f1d925bc5a1b7f0bd87",
      "87b1b2f7b32f47a1919bc77797c14907",
      "564bbad0a54d41a885e662eabdf0fc5d",
      "651cbb6abf7f4b8c8c5ad93921afc686"
     ]
    },
    "id": "LSFYS2tTEURV",
    "outputId": "f720aaf2-8619-4e7b-9725-b9d45784414a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef58bd9c9a0642d6bc3e01b06a520579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/41.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d0aae85ba714769bfd4ab6ea9a20ae0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/1024 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbac6dfffb804cf494f90d804ac0ea4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/1024 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22aa8fca9afa445f8dd5c48050a87aae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/255 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "437b972c286c4499898f4245e50a91b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/738 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "153253240d7c4f78aeb84cc7925213b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "332c233ba44e494984f01a1c15dab976",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "641fa99692c64b49a3f78a8d02927abc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4df2aa0b3bc4149801fd8e1c17f9e4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03394a9b5a5c4c8fbd75d448d3474fcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/118 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c64c51988ce34b2dbbc983171938e0ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All CLS and pooler embeddings saved under simcse_cls_embeddings\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Generate CLS embeddings for every hidden layer **and** the SimCSE‑trained `pooler_output`,\n",
    "then save them on disk batch‑by‑batch.\n",
    "\"\"\"\n",
    "\n",
    "# 30 000 short samples from C4 (demo size)\n",
    "ds    = load_dataset(\"allenai/c4\", \"en\", split=\"train\", streaming=True)\n",
    "texts = [ex[\"text\"] for ex in ds.shuffle(buffer_size=30_000, seed=42).take(30_000)]\n",
    "\n",
    "# =============================================================\n",
    "# 1.  Configuration\n",
    "# =============================================================\n",
    "MODEL_NAME = \"princeton-nlp/sup-simcse-roberta-base\"  # *** SimCSE ***\n",
    "SAVE_DIR   = \"simcse_cls_embeddings\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "MAX_LEN    = 256\n",
    "\n",
    "# =============================================================\n",
    "# 2.  Model & tokenizer\n",
    "# =============================================================\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "\n",
    "model = AutoModel.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    output_hidden_states=True,              # we need every layer\n",
    "    device_map=\"auto\" if device == \"cuda\" else None\n",
    ").eval()\n",
    "\n",
    "num_layers = model.config.num_hidden_layers + 1  # e.g. 13 for *-base (embeddings layer + 12 transformer layers)\n",
    "\n",
    "# =============================================================\n",
    "# 3.  Generation & saving of CLS + pooler embeddings\n",
    "# =============================================================\n",
    "\n",
    "problem_batches = []\n",
    "\n",
    "for batch_idx in tqdm(range(0, len(texts), BATCH_SIZE),\n",
    "                      total=(len(texts) + BATCH_SIZE - 1) // BATCH_SIZE):\n",
    "\n",
    "    batch_texts = texts[batch_idx: batch_idx + BATCH_SIZE]\n",
    "\n",
    "    inputs = tokenizer(\n",
    "        batch_texts,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=MAX_LEN,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)  # hidden_states + pooler_output\n",
    "\n",
    "    # ---------- CLS for every hidden layer ----------\n",
    "    for layer_idx, hs in enumerate(outputs.hidden_states):  # hs: [B, L, H]\n",
    "        cls_emb = hs[:, 0, :].cpu()                        # [B, H]\n",
    "\n",
    "        if torch.isinf(cls_emb).any():\n",
    "            problem_batches.append((batch_idx, f\"layer_{layer_idx}\"))\n",
    "\n",
    "        layer_dir = os.path.join(SAVE_DIR, f\"layer_{layer_idx}\")\n",
    "        os.makedirs(layer_dir, exist_ok=True)\n",
    "        torch.save(cls_emb, os.path.join(layer_dir, f\"batch_{batch_idx}.pt\"))\n",
    "\n",
    "    # ---------- SimCSE‑trained pooler_output ----------\n",
    "    if hasattr(outputs, \"pooler_output\") and outputs.pooler_output is not None:\n",
    "        pool_emb = outputs.pooler_output.cpu()  # [B, H]\n",
    "\n",
    "        if torch.isinf(pool_emb).any():\n",
    "            problem_batches.append((batch_idx, \"pooler\"))\n",
    "\n",
    "        pooler_dir = os.path.join(SAVE_DIR, \"pooler\")\n",
    "        os.makedirs(pooler_dir, exist_ok=True)\n",
    "        torch.save(pool_emb, os.path.join(pooler_dir, f\"batch_{batch_idx}.pt\"))\n",
    "\n",
    "    # ---------- housekeeping ----------\n",
    "    del outputs, inputs, cls_emb\n",
    "    if \"pool_emb\" in locals():\n",
    "        del pool_emb\n",
    "    gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "# =============================================================\n",
    "# 4.  Summary\n",
    "# =============================================================\n",
    "if problem_batches:\n",
    "    print(\"Found inf values in:\", problem_batches)\n",
    "print(f\"All CLS and pooler embeddings saved under {SAVE_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p-eOm_MWUdiT"
   },
   "outputs": [],
   "source": [
    "def load_layer_embeddings(layer_idx: int, num_layers = 13) -> torch.Tensor:\n",
    "    \"\"\"Return concatenated embeddings for `layer_idx`.\n",
    "    The last index (== num_layers) denotes the pooler_output.\"\"\"\n",
    "    if layer_idx == num_layers:   # pooler\n",
    "        layer_dir = os.path.join(SAVE_DIR, \"pooler\")\n",
    "    else:\n",
    "        layer_dir = os.path.join(SAVE_DIR, f\"layer_{layer_idx}\")\n",
    "\n",
    "    batch_files = sorted(layer_dir for layer_dir in os.listdir(layer_dir))\n",
    "    return torch.cat([torch.load(os.path.join(layer_dir, f)) for f in batch_files], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GBxv8EN5wcpf"
   },
   "outputs": [],
   "source": [
    "s = load_layer_embeddings(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a8cFk0cB9K2p"
   },
   "outputs": [],
   "source": [
    "for layer_idx in range(num_layers+1):\n",
    "  a = load_layer_embeddings(layer_idx)\n",
    "  if torch.isinf(a).sum() != 0:\n",
    "    print(f\"INF layer, {layer_idx}\")\n",
    "  if torch.isnan(a).sum() != 0:\n",
    "    print(f\"NANS layer, {layer_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hhMxKasuytsf"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "# === Настройка логгера ===\n",
    "def setup_logging(log_file):\n",
    "    logger = logging.getLogger(\"metrics_logger\")\n",
    "    logger.setLevel(logging.INFO)\n",
    "\n",
    "    if logger.hasHandlers():\n",
    "        logger.handlers.clear()\n",
    "\n",
    "    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "    file_handler = logging.FileHandler(log_file, mode='w')\n",
    "    file_handler.setFormatter(formatter)\n",
    "\n",
    "    console_handler = logging.StreamHandler()\n",
    "    console_handler.setFormatter(formatter)\n",
    "\n",
    "    logger.addHandler(file_handler)\n",
    "    logger.addHandler(console_handler)\n",
    "\n",
    "    return logger\n",
    "\n",
    "# === Подсчет метрики ===\n",
    "def calculate_metric(a, b, metric_name, batch_size=1000, trials=10):\n",
    "    cls = ALL_MEASURES[metric_name]\n",
    "    metrics = []\n",
    "\n",
    "    for i in range(trials):\n",
    "        idx = np.random.permutation(a.shape[0])[:batch_size]\n",
    "        metric = cls(a[idx], b[idx], shape='nd')\n",
    "        metrics.append(metric)\n",
    "\n",
    "    return np.mean(metrics), np.std(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jm-jS3EYyyLr"
   },
   "outputs": [],
   "source": [
    "PATH = '/content/drive/MyDrive/PTLS/NLP/SIM-SCE/'\n",
    "LOG_FILE = 'similarity_metrics.log'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8VLznbJsOv7C",
    "outputId": "3334b4e6-af91-409e-aeec-8a8e519fa783"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-22 10:07:38,751 - INFO - Finished DistanceCorrelation in 0:04:34.121221\n",
      "INFO:metrics_logger:Finished DistanceCorrelation in 0:04:34.121221\n",
      "2025-05-22 10:07:38,752 - INFO - === All metrics completed in 0:20:33.686556 ===\n",
      "INFO:metrics_logger:=== All metrics completed in 0:20:33.686556 ===\n"
     ]
    }
   ],
   "source": [
    "# === Константы ===\n",
    "METRICS = ['CKA', 'RSA', 'JaccardSimilarity', 'DistanceCorrelation']\n",
    "\n",
    "# === Инициализация логгера ===\n",
    "logger = setup_logging(LOG_FILE)\n",
    "\n",
    "# === Основной процесс ===\n",
    "try:\n",
    "    logger.info(\"=== Start metrics calculation ===\")\n",
    "    logger.info(f\"Metrics to compute: {', '.join(METRICS)}\")\n",
    "    start_time = datetime.now()\n",
    "\n",
    "    for metric_name in METRICS:\n",
    "        metric_start = datetime.now()\n",
    "        logger.info(f\"{'='*40}\\nProcessing: {metric_name}\")\n",
    "\n",
    "        matrix = np.zeros((num_layers+1, num_layers+1))\n",
    "        matrix_std = np.zeros((num_layers+1, num_layers+1))\n",
    "\n",
    "        for i in range(num_layers+1):\n",
    "            a = load_layer_embeddings(i)\n",
    "            logger.info(f\"Layer {i} | Shape: {a.shape}\")\n",
    "\n",
    "            for j in range(i, num_layers+1):\n",
    "                b = load_layer_embeddings(j)\n",
    "\n",
    "                try:\n",
    "                    metr, metr_std = calculate_metric(a.float(), b.float(), metric_name, batch_size=3000, trials=5)\n",
    "                    matrix[i, j] = matrix[j, i] = metr\n",
    "                    matrix_std[i, j] = matrix_std[j, i] = metr_std\n",
    "\n",
    "                    logger.info(f\"{metric_name} | L{i}-L{j}: {metr:.4f} ± {metr_std:.4f} | \"\n",
    "                                f\"GPU Mem: {torch.cuda.memory_allocated() / 1024**2:.1f} MB\")\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Metric error for L{i}-L{j}: {e}\", exc_info=True)\n",
    "\n",
    "                del b\n",
    "                torch.cuda.empty_cache()\n",
    "                gc.collect()\n",
    "                clear_output()\n",
    "\n",
    "            del a\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "        save_res(matrix, f\"{PATH}{metric_name}.pkl\")\n",
    "        save_res(matrix_std, f\"{PATH}{metric_name}_std.pkl\")\n",
    "\n",
    "        logger.info(f\"Finished {metric_name} in {datetime.now() - metric_start}\")\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logger.critical(f\"Fatal error: {e}\", exc_info=True)\n",
    "finally:\n",
    "    logger.info(f\"=== All metrics completed in {datetime.now() - start_time} ===\")\n",
    "    for handler in logger.handlers:\n",
    "        handler.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H57mIhNrTsE7"
   },
   "source": [
    "# Считаем метрики похожести разных слоев модели mean- токену + Pooler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bG_DavJyTsE9"
   },
   "source": [
    "Тексты для расчета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 515,
     "referenced_widgets": [
      "4613861ddd254dc095f4f28215830804",
      "7e064abd183b4512a7962f4a2c34be67",
      "4f9805f7ab4443b4b5b88eae46c1396f",
      "9b9c6103c62f40009a590d3b1656a8d0",
      "b0b6bdb28b6b442a804cd1d188832412",
      "cf3e39eb755544a4b3fbbcaa9edc9b46",
      "04b96c4e8b104d9c9d0ec3bce3d0ff0f",
      "c94bd1069ac44c8dbb85aa9bd8c74069",
      "dc32596e9f1f46ffae98a909868ac94a",
      "ce8247f65be241519fc51cac6001d74b",
      "9c10e55911724150afb30837486fcc1a",
      "1b3f2a4f506b4bfe957b3d0619e0a895",
      "60bafb0f357443fcaa78dbd9857af937",
      "982f5b9630084c9bb91d88314ab18b81",
      "292a38059c344c2f8bb0622805a25735",
      "c424788f64be4545958b7267aae2119c",
      "1ac3da02e016452598e381736c754cf4",
      "95afc985981d482ab10f276901c94131",
      "25aec2170b8142f1a503516974f9f100",
      "59b46839904d4026a4084cd472e3f7ef",
      "144d40d416c64e87864860493ede60df",
      "d29ce965afbc4092b51f25d4ebd8b7ea",
      "1df476c75f11429696e2f82df2dab1ea",
      "e403fffb243a42808848b0476ae83461",
      "bccbcbaba8a9466197e4ba9cb56e3917",
      "f78aaf8d3da34709bbe2319de4237d39",
      "dfe5ba822e0c40eab4d816ea6b5383c1",
      "550346adac0c4a34a6f64e1addb4e792",
      "7f46bc3910f74479afd96aa14c97ea37",
      "d7e9126be7714db4a1ac1668e4838e06",
      "b49928ab5a4641b19c8d510c97089526",
      "f2894ebbcfac4304811f3379f41174dc",
      "2339a8d658e74cdc90793b302d7729c2",
      "fec270b8eea34f2a9a1c816163e8fafb",
      "7b8e71cc7e8949d4b7a7ec20edbab2ce",
      "cf7bfcd18f72488e80ba7cbbfbfbc65a",
      "77f11b6aac32410380288d58ab9a8e8d",
      "779fae2382ea45b4be2abd74f51a6fba",
      "c204b49bd22e4fa7afb30185ac871960",
      "33b0e766f3a846239c7ffd5aff817fd4",
      "3b85048347984067a9cb59b7158e76ec",
      "c5e24fe33f59400690da8d061cae442a",
      "e7a30058b31143b6a13e27c074ff9611",
      "48c6b370ba6a4541b54588d7e1e3621c",
      "3f9324881ec54924b97b5f205dd39c5e",
      "7aeb86e74ff24f85bf18677cb99a4d4a",
      "aba2ddbc17f44767914509c915e0fc4d",
      "7e537438d7e74f8a855f517a6bd96d9a",
      "135eae0ba0c9481bb12d3dc21470d33b",
      "ca715836d98740afb60d554747ac8ef5",
      "9c178a3366134e7aba0ba19f89d63cae",
      "be249226196e4a6d983212a0c964071c",
      "d29043eb71104996b4cbe14a0b763d1a",
      "33c24325b8e54742bc544779a4436b9a",
      "06af7a0dd4ac4369a84717a3ce88f147",
      "5b34da7c9c144b2cac8e2f0850a4a40e",
      "1c1eed94be6b41b78ada8308a0e3e06a",
      "00c4ed7ceba14ed3b0c27560e62b9c40",
      "e0b926278a3f4dadb730dac10c49ae7e",
      "199c69373bbf41e69b745084a1290e34",
      "f7c97286dc14446aa62dc4f073188886",
      "c1324b164fd54ee896764994728f6d28",
      "abe050dec81745958f55c567888ff4ee",
      "28302eb20d3a4991ab5a17414c0db96e",
      "2612c0ff2f4c4d2d89246328cad2743f",
      "f8767a16d52c4be0a41e4ec009ba2eff",
      "6ba0dac90e6c46ee962a80fa13cae265",
      "5416cd9bced642058962b4cd3eee3d61",
      "1a8703614227434d9eb9e27b478d314a",
      "48c1bbe862044db89efd42d30a20ee0a",
      "26590ede56cf441ba85120da89ea6589",
      "11f127622ece4e4189364e33a3d8db54",
      "827bbadac667478781938d77609982b0",
      "1830580fd940446689923f79f967f66b",
      "adac3c1905ff4f01a7588fcddb54169f",
      "3727c1230741414fb8689007a38db2cb",
      "92ddf642f0f7418b8f8751cd470f8067",
      "4e540999963240fabe3f5768f3163621",
      "b79696d064fd44fb8f043e858257dddb",
      "d6233584924d4272979dbe9be678f459",
      "51dfd439d42e43cbbfe1b11ef211c23f",
      "24d290fbbbc948a081d50554d36a3ddc",
      "8f74edb85b01431f93cdf015183ae755",
      "19f3c89a6ce3484086ec9b1a10ef433b",
      "1946ac907219482ab703601ab1ba8ca9",
      "a8b00a8b393f40d98b00344532db360d",
      "f8afe2ab901d4cab9bc883dea783e193",
      "c5f9f2eb639c46b0ba79b153e8f6c94a",
      "2c6513588a544208965065b9a87b776c",
      "65e289a3ccd143e09bbc6c8b0aa9b8c0",
      "78aca4d8a4b44329859be37ce891d1e1",
      "a35d0cd0bc244d018d7cd39c9338d98b",
      "2947d2263e624cdaa5d6604004f1f734",
      "c79b39b994f4459890cb205e6d838789",
      "4bbc673afacb49e5b31b898d16ae0f2b",
      "b660a598cc474a3f891e1afb7d0bc4fe",
      "fd88bde700d14b09a5b103bdf14769d0",
      "76c9210fbd3d4ea5bfac60ae272567b7",
      "0046bbcff6de4afc9ef5de4db28fe597",
      "45cab8084b634d9398f0df2adfe6f483",
      "76a747a3da0c499fb0c6f6e2a7b1e138",
      "107f9a9dc8b9429fb9e560cd02ac8c2b",
      "2ae635dbf74340a79fb0ff9d28b3a4e1",
      "eb1adbf80dce4399b3ec126472ab2387",
      "fbeebaee3b674bd1b8207f692fafd9bd",
      "87cac3f1d265458a82fb1334cec888b9",
      "ca61a3761fbd46408b4352a50ee83ace",
      "e125c5c9c05e432ba871787c8deda78c",
      "788a814879a942d89ec316416d9b29d9",
      "15b3fed9ae52465cbf289c45e7ef5817",
      "3d9539d689c446e395c07d841d006a89",
      "ab0a0e75bed9478f95b874d75945f49f",
      "6d8e37dabadb40d88f090f0ff0c52947",
      "fea9d9921f474ea4829a7a30f990ce68",
      "8fda817d9a954ac69c95e404df4562ef",
      "80ae327cda51401eba602acdef29b984",
      "5ab199ca388a4580a2fd4d6fea593805",
      "d85ef1df819f4ec381e9d20a7433da45",
      "15aa7175bb794a949c404a986b775321",
      "da6b2d545a1a47b8879775197ca0e437",
      "2dcc09f23ce34801a06ec7bbfe0c458b"
     ]
    },
    "id": "bHlmoawDTsE-",
    "outputId": "d463e204-6e46-4df4-fe14-2a4a6111e0db"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4613861ddd254dc095f4f28215830804",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/41.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b3f2a4f506b4bfe957b3d0619e0a895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/1024 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1df476c75f11429696e2f82df2dab1ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/1024 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fec270b8eea34f2a9a1c816163e8fafb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/255 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f9324881ec54924b97b5f205dd39c5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/738 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b34da7c9c144b2cac8e2f0850a4a40e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ba0dac90e6c46ee962a80fa13cae265",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e540999963240fabe3f5768f3163621",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c6513588a544208965065b9a87b776c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45cab8084b634d9398f0df2adfe6f483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/118 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d9539d689c446e395c07d841d006a89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All mean-pooled and pooler embeddings saved under simcse_mean_embeddings\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Generate MEAN-pooled embeddings for every hidden layer **and** the SimCSE-trained\n",
    "`pooler_output`, then save them on disk batch-by-batch.\n",
    "\"\"\"\n",
    "\n",
    "import os, gc, torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# 30 000 short samples from C4 (demo size)\n",
    "ds    = load_dataset(\"allenai/c4\", \"en\", split=\"train\", streaming=True)\n",
    "texts = [ex[\"text\"] for ex in ds.shuffle(buffer_size=30_000, seed=42).take(30_000)]\n",
    "\n",
    "# =============================================================\n",
    "# 1.  Configuration\n",
    "# =============================================================\n",
    "MODEL_NAME = \"princeton-nlp/sup-simcse-roberta-base\"  # *** SimCSE ***\n",
    "SAVE_DIR   = \"simcse_mean_embeddings\"                 # ←- поменял имя директории\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "MAX_LEN    = 256\n",
    "\n",
    "# =============================================================\n",
    "# 2.  Model & tokenizer\n",
    "# =============================================================\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "\n",
    "model = AutoModel.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    output_hidden_states=True,     # нужно всё\n",
    "    device_map=\"auto\" if device == \"cuda\" else None\n",
    ").eval()\n",
    "\n",
    "num_layers = model.config.num_hidden_layers + 1  # embeddings + transformer layers\n",
    "\n",
    "# =============================================================\n",
    "# 3.  Generation & saving of MEAN + pooler embeddings\n",
    "# =============================================================\n",
    "\n",
    "problem_batches = []\n",
    "\n",
    "for batch_idx in tqdm(range(0, len(texts), BATCH_SIZE),\n",
    "                      total=(len(texts) + BATCH_SIZE - 1) // BATCH_SIZE):\n",
    "\n",
    "    batch_texts = texts[batch_idx: batch_idx + BATCH_SIZE]\n",
    "\n",
    "    inputs = tokenizer(\n",
    "        batch_texts,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=MAX_LEN,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)  # hidden_states + pooler_output\n",
    "\n",
    "    # ---------- MEAN over tokens for every hidden layer ----------\n",
    "# ---------- MEAN over non-padding tokens for every hidden layer ----------\n",
    "    attn_mask = inputs.attention_mask                     # [B, L], 1-для-токенов, 0-для-PAD\n",
    "    lengths   = attn_mask.sum(dim=1, keepdim=True)        # [B, 1]\n",
    "\n",
    "    # избегаем деления на 0 (может случиться, если строка обрезана целиком)\n",
    "    lengths = lengths.clamp(min=1)\n",
    "\n",
    "    # цикл по слоям\n",
    "    for layer_idx, hs in enumerate(outputs.hidden_states):   # hs: [B, L, H]\n",
    "        # обнуляем PAD-позиции и делим только на число непаддингов\n",
    "        summed = (hs * attn_mask.unsqueeze(-1)).sum(dim=1)   # [B, H]\n",
    "        mean_emb = summed / lengths                          # [B, H]\n",
    "\n",
    "        if torch.isinf(mean_emb).any():\n",
    "            problem_batches.append((batch_idx, f\"layer_{layer_idx}\"))\n",
    "\n",
    "        layer_dir = os.path.join(SAVE_DIR, f\"layer_{layer_idx}\")\n",
    "        os.makedirs(layer_dir, exist_ok=True)\n",
    "        torch.save(mean_emb.cpu(), os.path.join(layer_dir, f\"batch_{batch_idx}.pt\"))\n",
    "\n",
    "\n",
    "    # ---------- SimCSE-trained pooler_output ----------\n",
    "    if hasattr(outputs, \"pooler_output\") and outputs.pooler_output is not None:\n",
    "        pool_emb = outputs.pooler_output.cpu()  # [B, H]\n",
    "\n",
    "        if torch.isinf(pool_emb).any():\n",
    "            problem_batches.append((batch_idx, \"pooler\"))\n",
    "\n",
    "        pooler_dir = os.path.join(SAVE_DIR, \"pooler\")\n",
    "        os.makedirs(pooler_dir, exist_ok=True)\n",
    "        torch.save(pool_emb, os.path.join(pooler_dir, f\"batch_{batch_idx}.pt\"))\n",
    "\n",
    "    # ---------- housekeeping ----------\n",
    "    del outputs, inputs, mean_emb\n",
    "    if \"pool_emb\" in locals():\n",
    "        del pool_emb\n",
    "    gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "# =============================================================\n",
    "# 4.  Summary\n",
    "# =============================================================\n",
    "if problem_batches:\n",
    "    print(\"Found inf values in:\", problem_batches)\n",
    "print(f\"All mean-pooled and pooler embeddings saved under {SAVE_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gdzmDFsbTsFB"
   },
   "outputs": [],
   "source": [
    "def load_layer_embeddings(layer_idx: int, num_layers = 13) -> torch.Tensor:\n",
    "    \"\"\"Return concatenated embeddings for `layer_idx`.\n",
    "    The last index (== num_layers) denotes the pooler_output.\"\"\"\n",
    "    if layer_idx == num_layers:   # pooler\n",
    "        layer_dir = os.path.join(SAVE_DIR, \"pooler\")\n",
    "    else:\n",
    "        layer_dir = os.path.join(SAVE_DIR, f\"layer_{layer_idx}\")\n",
    "\n",
    "    batch_files = sorted(layer_dir for layer_dir in os.listdir(layer_dir))\n",
    "    return torch.cat([torch.load(os.path.join(layer_dir, f)) for f in batch_files], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0TpaPzjzTsFC"
   },
   "outputs": [],
   "source": [
    "s = load_layer_embeddings(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "28P3S_qvXGOw",
    "outputId": "caaf2e26-4d38-4c03-ab8c-7604d12ae343"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30000, 768])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gOzUYqDlTsFD"
   },
   "outputs": [],
   "source": [
    "for layer_idx in range(num_layers+1):\n",
    "  a = load_layer_embeddings(layer_idx)\n",
    "  if torch.isinf(a).sum() != 0:\n",
    "    print(f\"INF layer, {layer_idx}\")\n",
    "  if torch.isnan(a).sum() != 0:\n",
    "    print(f\"NANS layer, {layer_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R7c-dLzZTsFE"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "# === Настройка логгера ===\n",
    "def setup_logging(log_file):\n",
    "    logger = logging.getLogger(\"metrics_logger\")\n",
    "    logger.setLevel(logging.INFO)\n",
    "\n",
    "    if logger.hasHandlers():\n",
    "        logger.handlers.clear()\n",
    "\n",
    "    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "    file_handler = logging.FileHandler(log_file, mode='w')\n",
    "    file_handler.setFormatter(formatter)\n",
    "\n",
    "    console_handler = logging.StreamHandler()\n",
    "    console_handler.setFormatter(formatter)\n",
    "\n",
    "    logger.addHandler(file_handler)\n",
    "    logger.addHandler(console_handler)\n",
    "\n",
    "    return logger\n",
    "\n",
    "# === Подсчет метрики ===\n",
    "def calculate_metric(a, b, metric_name, batch_size=1000, trials=10):\n",
    "    cls = ALL_MEASURES[metric_name]\n",
    "    metrics = []\n",
    "\n",
    "    for i in range(trials):\n",
    "        idx = np.random.permutation(a.shape[0])[:batch_size]\n",
    "        metric = cls(a[idx], b[idx], shape='nd')\n",
    "        metrics.append(metric)\n",
    "\n",
    "    return np.mean(metrics), np.std(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y29mQiz-TsFF"
   },
   "outputs": [],
   "source": [
    "PATH = '/content/drive/MyDrive/PTLS/NLP/SIM-SCE/'\n",
    "LOG_FILE = 'similarity_metrics.log'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G8AChVjuXt5q"
   },
   "outputs": [],
   "source": [
    "num_layers = 13\n",
    "MODEL_NAME = \"princeton-nlp/sup-simcse-roberta-base\"  # *** SimCSE ***\n",
    "SAVE_DIR   = \"simcse_mean_embeddings\"                 # ←- поменял имя директории"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EsY9_DgPTsFG",
    "outputId": "d440d026-df5e-4d49-f95a-587038e892b2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-23 18:21:05,785 - INFO - Finished CKA in 0:01:14.676987\n",
      "INFO:metrics_logger:Finished CKA in 0:01:14.676987\n",
      "2025-05-23 18:21:05,786 - INFO - === All metrics completed in 0:01:14.678194 ===\n",
      "INFO:metrics_logger:=== All metrics completed in 0:01:14.678194 ===\n"
     ]
    }
   ],
   "source": [
    "# === Константы ===\n",
    "METRICS = ['CKA']#, 'RSA', 'JaccardSimilarity', 'DistanceCorrelation']\n",
    "\n",
    "# === Инициализация логгера ===\n",
    "logger = setup_logging(LOG_FILE)\n",
    "\n",
    "# === Основной процесс ===\n",
    "try:\n",
    "    logger.info(\"=== Start metrics calculation ===\")\n",
    "    logger.info(f\"Metrics to compute: {', '.join(METRICS)}\")\n",
    "    start_time = datetime.now()\n",
    "\n",
    "    for metric_name in METRICS:\n",
    "        metric_start = datetime.now()\n",
    "        logger.info(f\"{'='*40}\\nProcessing: {metric_name}\")\n",
    "\n",
    "        matrix = np.zeros((num_layers+1, num_layers+1))\n",
    "        matrix_std = np.zeros((num_layers+1, num_layers+1))\n",
    "\n",
    "        for i in range(num_layers+1):\n",
    "            a = load_layer_embeddings(i)\n",
    "            logger.info(f\"Layer {i} | Shape: {a.shape}\")\n",
    "\n",
    "            for j in range(i, num_layers+1):\n",
    "                b = load_layer_embeddings(j)\n",
    "\n",
    "                try:\n",
    "                    metr, metr_std = calculate_metric(a.float(), b.float(), metric_name, batch_size=5000, trials=5)\n",
    "                    matrix[i, j] = matrix[j, i] = metr\n",
    "                    matrix_std[i, j] = matrix_std[j, i] = metr_std\n",
    "\n",
    "                    logger.info(f\"{metric_name} | L{i}-L{j}: {metr:.4f} ± {metr_std:.4f} | \"\n",
    "                                f\"GPU Mem: {torch.cuda.memory_allocated() / 1024**2:.1f} MB\")\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Metric error for L{i}-L{j}: {e}\", exc_info=True)\n",
    "\n",
    "                del b\n",
    "                torch.cuda.empty_cache()\n",
    "                gc.collect()\n",
    "                clear_output()\n",
    "\n",
    "            del a\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "        save_res(matrix, f\"{PATH}{metric_name}_meanpool.pkl\")\n",
    "        save_res(matrix_std, f\"{PATH}{metric_name}_meanpool_std.pkl\")\n",
    "\n",
    "        logger.info(f\"Finished {metric_name} in {datetime.now() - metric_start}\")\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    logger.critical(f\"Fatal error: {e}\", exc_info=True)\n",
    "finally:\n",
    "    logger.info(f\"=== All metrics completed in {datetime.now() - start_time} ===\")\n",
    "    for handler in logger.handlers:\n",
    "        handler.close()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "rU69WGfu887H",
    "pPDELZtgg3Cl",
    "wl8_1tharCEA"
   ],
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
